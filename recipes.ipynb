{"cells":[{"cell_type":"code","source":["pip install Unidecode"],"metadata":{"id":"65wRctEDlXZi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7368bf12-7e0d-491d-9c27-310c3c54d6c0","executionInfo":{"status":"ok","timestamp":1668527746483,"user_tz":-180,"elapsed":6122,"user":{"displayName":"Татьяна П","userId":"02202781863895963642"}}},"id":"65wRctEDlXZi","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting Unidecode\n","  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n","\u001b[K     |████████████████████████████████| 235 kB 5.4 MB/s \n","\u001b[?25hInstalling collected packages: Unidecode\n","Successfully installed Unidecode-1.3.6\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.svm import SVR, SVC\n","from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor, BaggingRegressor, StackingRegressor\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, BaggingClassifier, StackingClassifier\n","from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n","from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, make_scorer\n","from joblib import dump, load\n","from sklearn.linear_model import LogisticRegression, LinearRegression\n","import math\n","import requests\n","import unidecode\n","from bs4 import BeautifulSoup\n","from googlesearch import search\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"ulb5b3X4lbOP"},"id":"ulb5b3X4lbOP","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"4d9d669d","metadata":{"id":"4d9d669d"},"source":["# Подготовка данных"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qYD1m4HblgLW","outputId":"c80d176e-834b-4fd9-a4c5-72b385767dd7"},"id":"qYD1m4HblgLW","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"id":"4fe8c0bc","metadata":{"scrolled":false,"colab":{"base_uri":"https://localhost:8080/","height":991},"id":"4fe8c0bc","outputId":"a84eb571-d47c-4e8e-fce5-63f5c2417a26"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             title  rating  calories  protein  \\\n","0                  Lentil, Apple, and Turkey Wrap    2.500     426.0     30.0   \n","1      Boudin Blanc Terrine with Red Onion Confit    4.375     403.0     18.0   \n","2                    Potato and Fennel Soup Hodge    3.750     165.0      6.0   \n","3                 Mahi-Mahi in Tomato Olive Sauce    5.000       NaN      NaN   \n","4                        Spinach Noodle Casserole    3.125     547.0     20.0   \n","...                                            ...     ...       ...      ...   \n","20047                              Parmesan Puffs    3.125      28.0      2.0   \n","20048              Artichoke and Parmesan Risotto    4.375     671.0     22.0   \n","20049                       Turkey Cream Puff Pie    4.375     563.0     31.0   \n","20050     Snapper on Angel Hair with Citrus Cream    4.375     631.0     45.0   \n","20051  Baked Ham with Marmalade-Horseradish Glaze    4.375     560.0     73.0   \n","\n","        fat  sodium  #cakeweek  #wasteless  22-minute meals  \\\n","0       7.0   559.0        0.0         0.0              0.0   \n","1      23.0  1439.0        0.0         0.0              0.0   \n","2       7.0   165.0        0.0         0.0              0.0   \n","3       NaN     NaN        0.0         0.0              0.0   \n","4      32.0   452.0        0.0         0.0              0.0   \n","...     ...     ...        ...         ...              ...   \n","20047   2.0    64.0        0.0         0.0              0.0   \n","20048  28.0   583.0        0.0         0.0              0.0   \n","20049  38.0   652.0        0.0         0.0              0.0   \n","20050  24.0   517.0        0.0         0.0              0.0   \n","20051  10.0  3698.0        0.0         0.0              0.0   \n","\n","       3-ingredient recipes  ...  yellow squash  yogurt  yonkers  yuca  \\\n","0                       0.0  ...            0.0     0.0      0.0   0.0   \n","1                       0.0  ...            0.0     0.0      0.0   0.0   \n","2                       0.0  ...            0.0     0.0      0.0   0.0   \n","3                       0.0  ...            0.0     0.0      0.0   0.0   \n","4                       0.0  ...            0.0     0.0      0.0   0.0   \n","...                     ...  ...            ...     ...      ...   ...   \n","20047                   0.0  ...            0.0     0.0      0.0   0.0   \n","20048                   0.0  ...            0.0     0.0      0.0   0.0   \n","20049                   0.0  ...            0.0     0.0      0.0   0.0   \n","20050                   0.0  ...            0.0     0.0      0.0   0.0   \n","20051                   0.0  ...            0.0     0.0      0.0   0.0   \n","\n","       zucchini  cookbooks  leftovers  snack  snack week  turkey  \n","0           0.0        0.0        0.0    0.0         0.0     1.0  \n","1           0.0        0.0        0.0    0.0         0.0     0.0  \n","2           0.0        0.0        0.0    0.0         0.0     0.0  \n","3           0.0        0.0        0.0    0.0         0.0     0.0  \n","4           0.0        0.0        0.0    0.0         0.0     0.0  \n","...         ...        ...        ...    ...         ...     ...  \n","20047       0.0        0.0        0.0    0.0         0.0     0.0  \n","20048       0.0        0.0        0.0    0.0         0.0     0.0  \n","20049       0.0        0.0        0.0    0.0         0.0     1.0  \n","20050       0.0        0.0        0.0    0.0         0.0     0.0  \n","20051       0.0        0.0        0.0    0.0         0.0     0.0  \n","\n","[20052 rows x 680 columns]"],"text/html":["\n","  <div id=\"df-c93f924e-cc2d-4729-9d48-1925be831b5f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>rating</th>\n","      <th>calories</th>\n","      <th>protein</th>\n","      <th>fat</th>\n","      <th>sodium</th>\n","      <th>#cakeweek</th>\n","      <th>#wasteless</th>\n","      <th>22-minute meals</th>\n","      <th>3-ingredient recipes</th>\n","      <th>...</th>\n","      <th>yellow squash</th>\n","      <th>yogurt</th>\n","      <th>yonkers</th>\n","      <th>yuca</th>\n","      <th>zucchini</th>\n","      <th>cookbooks</th>\n","      <th>leftovers</th>\n","      <th>snack</th>\n","      <th>snack week</th>\n","      <th>turkey</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Lentil, Apple, and Turkey Wrap</td>\n","      <td>2.500</td>\n","      <td>426.0</td>\n","      <td>30.0</td>\n","      <td>7.0</td>\n","      <td>559.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Boudin Blanc Terrine with Red Onion Confit</td>\n","      <td>4.375</td>\n","      <td>403.0</td>\n","      <td>18.0</td>\n","      <td>23.0</td>\n","      <td>1439.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Potato and Fennel Soup Hodge</td>\n","      <td>3.750</td>\n","      <td>165.0</td>\n","      <td>6.0</td>\n","      <td>7.0</td>\n","      <td>165.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Mahi-Mahi in Tomato Olive Sauce</td>\n","      <td>5.000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Spinach Noodle Casserole</td>\n","      <td>3.125</td>\n","      <td>547.0</td>\n","      <td>20.0</td>\n","      <td>32.0</td>\n","      <td>452.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>20047</th>\n","      <td>Parmesan Puffs</td>\n","      <td>3.125</td>\n","      <td>28.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>64.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>20048</th>\n","      <td>Artichoke and Parmesan Risotto</td>\n","      <td>4.375</td>\n","      <td>671.0</td>\n","      <td>22.0</td>\n","      <td>28.0</td>\n","      <td>583.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>20049</th>\n","      <td>Turkey Cream Puff Pie</td>\n","      <td>4.375</td>\n","      <td>563.0</td>\n","      <td>31.0</td>\n","      <td>38.0</td>\n","      <td>652.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>20050</th>\n","      <td>Snapper on Angel Hair with Citrus Cream</td>\n","      <td>4.375</td>\n","      <td>631.0</td>\n","      <td>45.0</td>\n","      <td>24.0</td>\n","      <td>517.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>20051</th>\n","      <td>Baked Ham with Marmalade-Horseradish Glaze</td>\n","      <td>4.375</td>\n","      <td>560.0</td>\n","      <td>73.0</td>\n","      <td>10.0</td>\n","      <td>3698.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>20052 rows × 680 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c93f924e-cc2d-4729-9d48-1925be831b5f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c93f924e-cc2d-4729-9d48-1925be831b5f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c93f924e-cc2d-4729-9d48-1925be831b5f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}],"source":["recipes = pd.read_csv('/content/drive/MyDrive/Школа 21/DS_project 15 Создание прототипа рекомендательного сервиса рецептов/epi_r.csv')\n","recipes"]},{"cell_type":"code","source":["df = pd.DataFrame(recipes.columns)\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"sOEid17f8llE","outputId":"72a129b2-bb08-4466-d05b-27ce9344e1d0"},"id":"sOEid17f8llE","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              0\n","0         title\n","1        rating\n","2      calories\n","3       protein\n","4           fat\n","..          ...\n","675   cookbooks\n","676   leftovers\n","677       snack\n","678  snack week\n","679      turkey\n","\n","[680 rows x 1 columns]"],"text/html":["\n","  <div id=\"df-36ae87b6-5a49-4b13-8f64-7275998b0447\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>title</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>rating</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>calories</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>protein</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>fat</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>675</th>\n","      <td>cookbooks</td>\n","    </tr>\n","    <tr>\n","      <th>676</th>\n","      <td>leftovers</td>\n","    </tr>\n","    <tr>\n","      <th>677</th>\n","      <td>snack</td>\n","    </tr>\n","    <tr>\n","      <th>678</th>\n","      <td>snack week</td>\n","    </tr>\n","    <tr>\n","      <th>679</th>\n","      <td>turkey</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>680 rows × 1 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36ae87b6-5a49-4b13-8f64-7275998b0447')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-36ae87b6-5a49-4b13-8f64-7275998b0447 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-36ae87b6-5a49-4b13-8f64-7275998b0447');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["#сохранила в excel чтобы открыть поизучать\n","df.to_excel('/content/drive/MyDrive/Школа 21/epi_r.xls')"],"metadata":{"id":"I1119ubmm7ed"},"id":"I1119ubmm7ed","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"2e82a4a5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2e82a4a5","outputId":"291b47a7-4bc8-4ca0-9af2-10c47b4d1af5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(20052, 680)"]},"metadata":{},"execution_count":14}],"source":["recipes.shape"]},{"cell_type":"code","execution_count":null,"id":"cbcb7f34","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cbcb7f34","outputId":"04406816-e273-4153-ef5a-f2374c55f1f2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["274"]},"metadata":{},"execution_count":5}],"source":["#отбираем нужные колонки\n","selected_columns = [\n","'title','rating','calories','protein','fat','sodium','breakfast','lunch','dinner','almond','amaretto','anchovy','anise','apple',\n","'apple juice','apricot','artichoke','arugula','asian pear','asparagus','aspen','avocado','bacon','banana','barley','basil',\n","'bass','bean','beef','beef rib','beef shank','beef tenderloin','beer','beet','bell pepper','blackberry','blue cheese',\n","'blueberry','bok choy','bourbon','bran','brandy','bread','breadcrumbs','brie','brisket','broccoli','broccoli rabe','brown rice',\n","'brussel sprout','bulgur','butter','buttermilk','cabbage','cantaloupe','capers','caraway','cardamom','carrot','cashew',\n","'cauliflower','caviar','celery','champagne','cheddar','cheese','cherry','chestnut','chicken','chickpea','chile pepper',\n","'chocolate','cilantro','cinnamon','clam','clove','coconut','cod','coffee','collard greens','coriander','corn','cornmeal',\n","'cottage cheese','crab','cranberry','cranberry sauce','cream cheese','cucumber','cumin','currant','curry','dill','duck','egg',\n","'eggplant','fennel','feta','fig','fortified wine','garlic','gin','goat cheese','goose','gouda','grape','grapefruit',\n","'green bean','green onion/scallion','ground beef','ground lamb','guava','halibut','ham','hazelnut','honey','horseradish',\n","'hot pepper','jerusalem artichoke','kirsch','kiwi','lamb','lamb shank','leek','lemon','lemon juice','lemongrass','lentil',\n","'lettuce','lima bean','lime juice','lingonberry','lobster','lychee','macadamia nut','mango','maple syrup','martini',\n","'mayonnaise','melon','milk/cream','mint','mozzarella','mushroom','mussel','mustard','mustard greens','nectarine','noodle',\n","'nut','nutmeg','oat','octopus','olive','onion','orange','orange juice','oregano','oyster','papaya','paprika','parmesan',\n","'parsley','parsnip','passion fruit','pasta','pea','peach','peanut','peanut butter','pear','pecan','pepper','persimmon',\n","'phyllo/puff pastry dough','pickles','pine nut','pineapple','pistachio','plum','pomegranate','pomegranate juice','poppy','pork',\n","'pork chop','pork rib','pork tenderloin','potato','prosciutto','prune','pumpkin','quail','quiche','quince','quinoa','rabbit',\n","'radicchio','radish','raisin','raspberry','red wine','rhubarb','rice','ricotta','rosemary','rum','rutabaga','rye','saffron',\n","'sage','sake','salad','salmon','sangria','sardine','sausage','scallop','scotch','seafood','semolina','sesame','sesame oil',\n","'shallot','shellfish','sherry','shrimp','sour cream','sourdough','soy','soy sauce','sparkling wine','spinach','squash','squid',\n","'stew','strawberry','sweet potato/yam','swiss cheese','swordfish','taco','tamarind','tangerine','tapioca','tarragon','tea',\n","'tequila','thyme','tilapia','tofu','tomatillo','tomato','tortillas','trout','tuna','turnip','vanilla','veal','venison',\n","'vermouth','vinegar','vodka','walnut','wasabi','watercress','watermelon','whiskey','white wine','wild rice','wine',\n","'yellow squash','yogurt','yuca','zucchini','turkey'\n","]\n","len(selected_columns)"]},{"cell_type":"code","execution_count":null,"id":"4646f5a7","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":973},"id":"4646f5a7","outputId":"18844310-02ad-474e-c58f-5a1b17a4cc16"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             title  rating  calories  protein  \\\n","0                  Lentil, Apple, and Turkey Wrap    2.500     426.0     30.0   \n","1      Boudin Blanc Terrine with Red Onion Confit    4.375     403.0     18.0   \n","2                    Potato and Fennel Soup Hodge    3.750     165.0      6.0   \n","3                 Mahi-Mahi in Tomato Olive Sauce    5.000       NaN      NaN   \n","4                        Spinach Noodle Casserole    3.125     547.0     20.0   \n","...                                            ...     ...       ...      ...   \n","20047                              Parmesan Puffs    3.125      28.0      2.0   \n","20048              Artichoke and Parmesan Risotto    4.375     671.0     22.0   \n","20049                       Turkey Cream Puff Pie    4.375     563.0     31.0   \n","20050     Snapper on Angel Hair with Citrus Cream    4.375     631.0     45.0   \n","20051  Baked Ham with Marmalade-Horseradish Glaze    4.375     560.0     73.0   \n","\n","        fat  sodium  breakfast  lunch  dinner  almond  ...  watermelon  \\\n","0       7.0   559.0        0.0    0.0     0.0     0.0  ...         0.0   \n","1      23.0  1439.0        0.0    0.0     0.0     0.0  ...         0.0   \n","2       7.0   165.0        0.0    0.0     0.0     0.0  ...         0.0   \n","3       NaN     NaN        0.0    0.0     1.0     0.0  ...         0.0   \n","4      32.0   452.0        0.0    0.0     0.0     0.0  ...         0.0   \n","...     ...     ...        ...    ...     ...     ...  ...         ...   \n","20047   2.0    64.0        0.0    0.0     0.0     0.0  ...         0.0   \n","20048  28.0   583.0        0.0    0.0     1.0     0.0  ...         0.0   \n","20049  38.0   652.0        0.0    0.0     1.0     0.0  ...         0.0   \n","20050  24.0   517.0        0.0    0.0     0.0     0.0  ...         0.0   \n","20051  10.0  3698.0        0.0    0.0     0.0     0.0  ...         0.0   \n","\n","       whiskey  white wine  wild rice  wine  yellow squash  yogurt  yuca  \\\n","0          0.0         0.0        0.0   0.0            0.0     0.0   0.0   \n","1          0.0         0.0        0.0   0.0            0.0     0.0   0.0   \n","2          0.0         0.0        0.0   0.0            0.0     0.0   0.0   \n","3          0.0         0.0        0.0   0.0            0.0     0.0   0.0   \n","4          0.0         0.0        0.0   0.0            0.0     0.0   0.0   \n","...        ...         ...        ...   ...            ...     ...   ...   \n","20047      0.0         0.0        0.0   0.0            0.0     0.0   0.0   \n","20048      0.0         0.0        0.0   0.0            0.0     0.0   0.0   \n","20049      0.0         0.0        0.0   0.0            0.0     0.0   0.0   \n","20050      0.0         0.0        0.0   0.0            0.0     0.0   0.0   \n","20051      0.0         0.0        0.0   0.0            0.0     0.0   0.0   \n","\n","       zucchini  turkey  \n","0           0.0     1.0  \n","1           0.0     0.0  \n","2           0.0     0.0  \n","3           0.0     0.0  \n","4           0.0     0.0  \n","...         ...     ...  \n","20047       0.0     0.0  \n","20048       0.0     0.0  \n","20049       0.0     1.0  \n","20050       0.0     0.0  \n","20051       0.0     0.0  \n","\n","[20052 rows x 274 columns]"],"text/html":["\n","  <div id=\"df-d2dc9bef-a955-43ff-99ef-8069fe73af18\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>rating</th>\n","      <th>calories</th>\n","      <th>protein</th>\n","      <th>fat</th>\n","      <th>sodium</th>\n","      <th>breakfast</th>\n","      <th>lunch</th>\n","      <th>dinner</th>\n","      <th>almond</th>\n","      <th>...</th>\n","      <th>watermelon</th>\n","      <th>whiskey</th>\n","      <th>white wine</th>\n","      <th>wild rice</th>\n","      <th>wine</th>\n","      <th>yellow squash</th>\n","      <th>yogurt</th>\n","      <th>yuca</th>\n","      <th>zucchini</th>\n","      <th>turkey</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Lentil, Apple, and Turkey Wrap</td>\n","      <td>2.500</td>\n","      <td>426.0</td>\n","      <td>30.0</td>\n","      <td>7.0</td>\n","      <td>559.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Boudin Blanc Terrine with Red Onion Confit</td>\n","      <td>4.375</td>\n","      <td>403.0</td>\n","      <td>18.0</td>\n","      <td>23.0</td>\n","      <td>1439.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Potato and Fennel Soup Hodge</td>\n","      <td>3.750</td>\n","      <td>165.0</td>\n","      <td>6.0</td>\n","      <td>7.0</td>\n","      <td>165.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Mahi-Mahi in Tomato Olive Sauce</td>\n","      <td>5.000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Spinach Noodle Casserole</td>\n","      <td>3.125</td>\n","      <td>547.0</td>\n","      <td>20.0</td>\n","      <td>32.0</td>\n","      <td>452.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>20047</th>\n","      <td>Parmesan Puffs</td>\n","      <td>3.125</td>\n","      <td>28.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>64.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>20048</th>\n","      <td>Artichoke and Parmesan Risotto</td>\n","      <td>4.375</td>\n","      <td>671.0</td>\n","      <td>22.0</td>\n","      <td>28.0</td>\n","      <td>583.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>20049</th>\n","      <td>Turkey Cream Puff Pie</td>\n","      <td>4.375</td>\n","      <td>563.0</td>\n","      <td>31.0</td>\n","      <td>38.0</td>\n","      <td>652.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>20050</th>\n","      <td>Snapper on Angel Hair with Citrus Cream</td>\n","      <td>4.375</td>\n","      <td>631.0</td>\n","      <td>45.0</td>\n","      <td>24.0</td>\n","      <td>517.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>20051</th>\n","      <td>Baked Ham with Marmalade-Horseradish Glaze</td>\n","      <td>4.375</td>\n","      <td>560.0</td>\n","      <td>73.0</td>\n","      <td>10.0</td>\n","      <td>3698.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>20052 rows × 274 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2dc9bef-a955-43ff-99ef-8069fe73af18')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d2dc9bef-a955-43ff-99ef-8069fe73af18 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d2dc9bef-a955-43ff-99ef-8069fe73af18');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}],"source":["recipes = recipes[selected_columns]\n","recipes"]},{"cell_type":"code","execution_count":null,"id":"3b1f1a1e","metadata":{"id":"3b1f1a1e"},"outputs":[],"source":["recipes = recipes.rename(columns={'green onion/scallion': 'green onion',\n","                   'milk/cream': 'milk',\n","                   'sweet potato/yam': 'sweet potato',\n","                   'phyllo/puff pastry dough': 'phyllo'\n","                  })"]},{"cell_type":"code","execution_count":null,"id":"8b83a0ad","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":505},"id":"8b83a0ad","outputId":"77ce2f7c-6473-43d4-cb06-a54b5f613923"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["       rating  almond  amaretto  anchovy  anise  apple  apple juice  apricot  \\\n","0       2.500     0.0       0.0      0.0    0.0    1.0          0.0      0.0   \n","1       4.375     0.0       0.0      0.0    0.0    0.0          0.0      0.0   \n","2       3.750     0.0       0.0      0.0    0.0    0.0          0.0      0.0   \n","3       5.000     0.0       0.0      0.0    0.0    0.0          0.0      0.0   \n","4       3.125     0.0       0.0      0.0    0.0    0.0          0.0      0.0   \n","...       ...     ...       ...      ...    ...    ...          ...      ...   \n","20047   3.125     0.0       0.0      0.0    0.0    0.0          0.0      0.0   \n","20048   4.375     0.0       0.0      0.0    0.0    0.0          0.0      0.0   \n","20049   4.375     0.0       0.0      0.0    0.0    0.0          0.0      0.0   \n","20050   4.375     0.0       0.0      0.0    0.0    0.0          0.0      0.0   \n","20051   4.375     0.0       0.0      0.0    0.0    0.0          0.0      0.0   \n","\n","       artichoke  arugula  ...  watermelon  whiskey  white wine  wild rice  \\\n","0            0.0      0.0  ...         0.0      0.0         0.0        0.0   \n","1            0.0      0.0  ...         0.0      0.0         0.0        0.0   \n","2            0.0      0.0  ...         0.0      0.0         0.0        0.0   \n","3            0.0      0.0  ...         0.0      0.0         0.0        0.0   \n","4            0.0      0.0  ...         0.0      0.0         0.0        0.0   \n","...          ...      ...  ...         ...      ...         ...        ...   \n","20047        0.0      0.0  ...         0.0      0.0         0.0        0.0   \n","20048        1.0      0.0  ...         0.0      0.0         0.0        0.0   \n","20049        0.0      0.0  ...         0.0      0.0         0.0        0.0   \n","20050        0.0      0.0  ...         0.0      0.0         0.0        0.0   \n","20051        0.0      0.0  ...         0.0      0.0         0.0        0.0   \n","\n","       wine  yellow squash  yogurt  yuca  zucchini  turkey  \n","0       0.0            0.0     0.0   0.0       0.0     1.0  \n","1       0.0            0.0     0.0   0.0       0.0     0.0  \n","2       0.0            0.0     0.0   0.0       0.0     0.0  \n","3       0.0            0.0     0.0   0.0       0.0     0.0  \n","4       0.0            0.0     0.0   0.0       0.0     0.0  \n","...     ...            ...     ...   ...       ...     ...  \n","20047   0.0            0.0     0.0   0.0       0.0     0.0  \n","20048   0.0            0.0     0.0   0.0       0.0     0.0  \n","20049   0.0            0.0     0.0   0.0       0.0     1.0  \n","20050   0.0            0.0     0.0   0.0       0.0     0.0  \n","20051   0.0            0.0     0.0   0.0       0.0     0.0  \n","\n","[20052 rows x 266 columns]"],"text/html":["\n","  <div id=\"df-55affe4f-04a7-4257-b33c-b952587c7309\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>rating</th>\n","      <th>almond</th>\n","      <th>amaretto</th>\n","      <th>anchovy</th>\n","      <th>anise</th>\n","      <th>apple</th>\n","      <th>apple juice</th>\n","      <th>apricot</th>\n","      <th>artichoke</th>\n","      <th>arugula</th>\n","      <th>...</th>\n","      <th>watermelon</th>\n","      <th>whiskey</th>\n","      <th>white wine</th>\n","      <th>wild rice</th>\n","      <th>wine</th>\n","      <th>yellow squash</th>\n","      <th>yogurt</th>\n","      <th>yuca</th>\n","      <th>zucchini</th>\n","      <th>turkey</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2.500</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.375</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3.750</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5.000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3.125</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>20047</th>\n","      <td>3.125</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>20048</th>\n","      <td>4.375</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>20049</th>\n","      <td>4.375</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>20050</th>\n","      <td>4.375</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>20051</th>\n","      <td>4.375</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>20052 rows × 266 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55affe4f-04a7-4257-b33c-b952587c7309')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-55affe4f-04a7-4257-b33c-b952587c7309 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-55affe4f-04a7-4257-b33c-b952587c7309');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}],"source":["df = recipes.drop(columns=['title','calories','protein','fat','sodium','breakfast','lunch','dinner'])\n","df"]},{"cell_type":"code","execution_count":null,"id":"88187c82","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"88187c82","outputId":"ecb9e8d8-242e-49e0-bc6b-ce7a4f22bf9d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["4532"]},"metadata":{},"execution_count":9}],"source":["df.duplicated().sum()"]},{"cell_type":"code","execution_count":null,"id":"f4567570","metadata":{"id":"f4567570"},"outputs":[],"source":["df.drop_duplicates(inplace=True)"]},{"cell_type":"code","execution_count":null,"id":"ae53ca78","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ae53ca78","outputId":"ac9723ff-bb4c-4852-dad0-ac6aaa437354"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(15520, 266)"]},"metadata":{},"execution_count":11}],"source":["df.shape"]},{"cell_type":"code","execution_count":null,"id":"c4b33105","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c4b33105","outputId":"c73bb308-0e88-4cb8-a99d-0ed5c2ffc0f4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["8"]},"metadata":{},"execution_count":12}],"source":["sum(df.drop(columns=['rating']).apply(sum, axis=1) == 0.0)"]},{"cell_type":"code","execution_count":null,"id":"6af7a85c","metadata":{"id":"6af7a85c"},"outputs":[],"source":["df = df[df.drop(columns=['rating']).apply(sum, axis=1) != 0.0]"]},{"cell_type":"code","execution_count":null,"id":"9234856d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9234856d","outputId":"33a7f208-8963-48c8-a1ef-a6f4a381f2a7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(15512, 266)"]},"metadata":{},"execution_count":14}],"source":["df.shape"]},{"cell_type":"code","execution_count":null,"id":"251b9bb3","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"251b9bb3","outputId":"97b12342-d505-4626-e9e1-f3989020a29b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.000    0.080905\n","1.250    0.008961\n","1.875    0.006704\n","2.500    0.028752\n","3.125    0.079358\n","3.750    0.261797\n","4.375    0.404332\n","5.000    0.129190\n","Name: rating, dtype: float64"]},"metadata":{},"execution_count":16}],"source":["df.rating.value_counts(normalize=True).sort_index()"]},{"cell_type":"code","execution_count":null,"id":"f0708fd1","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":570},"id":"f0708fd1","outputId":"eb2c7f79-36ce-4bc3-fc94-aaee6f548a39"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 864x648 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["df.rating.value_counts().sort_index().plot(kind='bar', xlabel='Rating', ylabel='Count', figsize=(12, 9));"]},{"cell_type":"code","source":["df.to_csv('/content/drive/MyDrive/Школа 21/DS_project 15 Создание прототипа рекомендательного сервиса рецептов/df.csv', index=False)"],"metadata":{"id":"xWRxqvX7t0qy"},"id":"xWRxqvX7t0qy","execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/Школа 21/DS_project 15 Создание прототипа рекомендательного сервиса рецептов/df.csv')"],"metadata":{"id":"5Tp0EGAEt64r"},"id":"5Tp0EGAEt64r","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"11609ab6","metadata":{"id":"11609ab6"},"source":["# Прогноз"]},{"cell_type":"markdown","id":"ec4baf29","metadata":{"id":"ec4baf29"},"source":["## Регрессия"]},{"cell_type":"code","execution_count":null,"id":"dc6e81ec","metadata":{"id":"dc6e81ec"},"outputs":[],"source":["X = df.drop(columns=['rating'])\n","y = df['rating']"]},{"cell_type":"code","execution_count":null,"id":"82092c13","metadata":{"id":"82092c13"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)"]},{"cell_type":"code","execution_count":null,"id":"b71bf2ba","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b71bf2ba","outputId":"8bf7c4c7-754a-4587-801d-8e2bc90d0c5e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.000    0.080909\n","1.250    0.008945\n","1.875    0.006689\n","2.500    0.028769\n","3.125    0.079378\n","3.750    0.261826\n","4.375    0.404303\n","5.000    0.129180\n","Name: rating, dtype: float64"]},"metadata":{},"execution_count":20}],"source":["y_train.value_counts(normalize=True).sort_index()"]},{"cell_type":"code","execution_count":null,"id":"575e49f5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"575e49f5","outputId":"e3fa560a-7dba-4c4c-c3ad-e10cc07a62e8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.000    0.080889\n","1.250    0.009024\n","1.875    0.006768\n","2.500    0.028682\n","3.125    0.079278\n","3.750    0.261682\n","4.375    0.404447\n","5.000    0.129230\n","Name: rating, dtype: float64"]},"metadata":{},"execution_count":21}],"source":["y_test.value_counts(normalize=True).sort_index()"]},{"cell_type":"markdown","id":"875a9ad0","metadata":{"id":"875a9ad0"},"source":["### LinearRegression"]},{"cell_type":"code","execution_count":null,"id":"a51ac5a3","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"a51ac5a3","outputId":"ac04d9e4-054d-4b8a-99aa-f73cab89b921"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'fit_intercept': True}, -1.2438508045243408e+22)"]},"metadata":{},"execution_count":32}],"source":["param_grid = {'fit_intercept': (True, False)}\n","\n","lin_reg = GridSearchCV(estimator=LinearRegression(), param_grid=param_grid, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n","lin_reg.fit(X_train, y_train)\n","lin_reg.best_params_, lin_reg.best_score_"]},{"cell_type":"code","execution_count":null,"id":"6b151a15","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6b151a15","outputId":"b1f2e863-0521-4f62-e55d-f533aa3877ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE LinearRegression на тестовой подвыборке: 1.2387249807151004\n"]}],"source":["print('RMSE LinearRegression на тестовой подвыборке:', math.sqrt(mean_squared_error(y_test, lin_reg.best_estimator_.predict(X_test))))"]},{"cell_type":"code","source":["#lin_reg_best = LinearRegression(fit_intercept = True)\n","#print('RMSE LinearRegression на тестовой подвыборке:', cross_val_score(lin_reg_best, X_test, y_test, cv=10, scoring='neg_mean_squared_error').mean())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TRxhV54FCtY-","outputId":"c2860f6a-8cc8-43ee-bb94-77d7cb3a2ced"},"id":"TRxhV54FCtY-","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE LinearRegression на тестовой подвыборке: -7.165845234176245e+24\n"]}]},{"cell_type":"markdown","id":"04298bde","metadata":{"id":"04298bde"},"source":["### DecisionTreeRegressor"]},{"cell_type":"code","source":["param_grid = {'max_depth' : range(1, 100)}\n","\n","tree_reg = GridSearchCV(estimator=DecisionTreeRegressor(), param_grid=param_grid, n_jobs=-1, cv=5, scoring='neg_mean_squared_error') \n","tree_reg.fit(X_train, y_train) \n","tree_reg.best_params_, tree_reg.best_score_"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vEJL5CKr6uyh","outputId":"4e37d4d5-d1ed-466b-ba44-6387dc133d9d"},"id":"vEJL5CKr6uyh","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'max_depth': 2}, -1.6174855208077745)"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","execution_count":null,"id":"58a73ae9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"58a73ae9","outputId":"7e779929-09a2-4bf0-b079-8805cf88f3f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE DecisionTreeRegressor на тестовой подвыборке: 1.270514577302714\n"]}],"source":["print('RMSE DecisionTreeRegressor на тестовой подвыборке:', math.sqrt(mean_squared_error(y_test, tree_reg.best_estimator_.predict(X_test))))"]},{"cell_type":"markdown","id":"6742ff49","metadata":{"id":"6742ff49"},"source":["### RandomForestRegressor"]},{"cell_type":"code","source":["param_grid = {'n_estimators' : range(10, 101, 10),\n","              'max_depth' : (1, 5, 10, 50, 100),\n","              'max_features' : (5, 10, 50, 100)}\n","forest_reg = GridSearchCV(estimator=RandomForestRegressor(random_state=21),\n","                      param_grid=param_grid, \n","                      cv=5,\n","                      scoring='neg_mean_squared_error', \n","                      n_jobs=-1)\n","forest_reg.fit(X_train, y_train)\n","forest_reg.best_params_, forest_reg.best_score_"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1a0hzJB2-QRD","outputId":"7a84a88f-cd8d-4ac9-bc02-d6ea06132da2"},"id":"1a0hzJB2-QRD","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'max_depth': 10, 'max_features': 50, 'n_estimators': 100},\n"," -1.5889910304784336)"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","execution_count":null,"id":"0989a8bd","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0989a8bd","outputId":"fb3cc277-2e9c-4804-8e9a-fa3d82d2866e"},"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE RandomForestRegressor на тестовой подвыборке: 1.25615848495156\n"]}],"source":["print('RMSE RandomForestRegressor на тестовой подвыборке:', math.sqrt(mean_squared_error(y_test, forest_reg.best_estimator_.predict(X_test))))"]},{"cell_type":"markdown","id":"85d03ede","metadata":{"id":"85d03ede"},"source":["### SVR"]},{"cell_type":"code","execution_count":null,"id":"98561a21","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"98561a21","outputId":"c081c095-279a-4a77-9679-946cd23bcfbe"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}, -1.7016849608428894)"]},"metadata":{},"execution_count":48}],"source":["param_grid = {'kernel': ('poly', 'rbf', 'sigmoid'),\n","              'gamma': ('scale', 'auto'),\n","              'C': (0.1, 1, 10)}\n","svr = GridSearchCV(estimator=SVR(),\n","                      param_grid=param_grid, \n","                      cv=5,\n","                      scoring='neg_mean_squared_error')\n","svr.fit(X_train, y_train)\n","svr.best_params_, svr.best_score_"]},{"cell_type":"code","execution_count":null,"id":"b00fb4d7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b00fb4d7","outputId":"44d98905-8d17-419c-f6ae-e54366a5c223"},"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE SVR на тестовой подвыборке: 1.3017944436276825\n"]}],"source":["print('RMSE SVR на тестовой подвыборке:', math.sqrt(mean_squared_error(y_test, svr.best_estimator_.predict(X_test))))"]},{"cell_type":"markdown","id":"2a4672ce","metadata":{"id":"2a4672ce"},"source":["### GradientBoostingRegressor"]},{"cell_type":"code","execution_count":null,"id":"456f0a07","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"456f0a07","outputId":"f743e517-8dff-4f22-e2ee-e0e9ba6d8a57"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=5, estimator=GradientBoostingRegressor(random_state=21),\n","             n_jobs=-1,\n","             param_grid={'max_depth': (1, 2, 5, 10, 15, 20),\n","                         'n_estimators': range(10, 101, 10)},\n","             scoring='neg_mean_squared_error')"]},"metadata":{},"execution_count":22}],"source":["param_grid = {'n_estimators' : range(10, 101, 10),\n","              'max_depth' : (1, 2, 5, 10, 15, 20)}\n","gboost_reg = GridSearchCV(estimator=GradientBoostingRegressor(random_state=21),\n","                      param_grid=param_grid, \n","                      cv=5,\n","                      scoring='neg_mean_squared_error', \n","                      n_jobs=-1)\n","gboost_reg.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"id":"65346a66","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"65346a66","outputId":"19dac2a5-7ddc-4db6-a048-8946aa720a7a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'max_depth': 2, 'n_estimators': 100}, -1.5824737179539747)"]},"metadata":{},"execution_count":23}],"source":["gboost_reg.best_params_, gboost_reg.best_score_"]},{"cell_type":"code","execution_count":null,"id":"f42c4824","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f42c4824","outputId":"8f2d7b07-5bee-4fb3-cbe3-cd870e40d9ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE GradientBoostingRegressor на тестовой подвыборке: 1.251648674424281\n"]}],"source":["print('RMSE GradientBoostingRegressor на тестовой подвыборке:', math.sqrt(mean_squared_error(y_test, gboost_reg.best_estimator_.predict(X_test))))"]},{"cell_type":"markdown","id":"9f467eb6","metadata":{"id":"9f467eb6"},"source":["### VotingRegressor"]},{"cell_type":"code","execution_count":null,"id":"e8350fe7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e8350fe7","outputId":"f29e498d-559f-4cce-c7c7-f9376990d0e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Best params: {'weights': [1, 1, 2]}, RMSE is 1.262857713732354\n"]}],"source":["best_RMSE = np.inf\n","best_params = 0\n","for weight_1 in range(1, 3):\n","      for weight_2 in range(1, 3):\n","        for weight_3 in range(1, 3):\n","            vr = VotingRegressor(estimators=[('SVR', SVR(C=1,\n","                                                         gamma='scale',\n","                                                         kernel='rbf')),\n","                                             ('DecisionTreeRegressor', DecisionTreeRegressor(max_depth=2)),\n","                                             ('RandomForestRegressor', RandomForestRegressor(random_state=21, \n","                                                                                             max_depth=10,\n","                                                                                             max_features=50,\n","                                                                                             n_estimators=100, \n","                                                                                             n_jobs=-1))],\n","                                 weights=[weight_1, weight_2, weight_3],\n","                                 n_jobs=-1)\n","            RMSE = math.sqrt(abs(cross_val_score(vr, X_train, y_train, cv=5, scoring='neg_mean_squared_error').mean()))\n","            if RMSE < best_RMSE:\n","                best_RMSE = RMSE\n","                best_params = {'weights': [weight_1, weight_2, weight_3]}\n","\n","\n","print(f'Best params: {best_params}, RMSE is {best_RMSE}')"]},{"cell_type":"code","execution_count":null,"id":"687d788c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"687d788c","outputId":"1f3fc49d-fbab-4b27-fd07-1332ed5e46f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE VotingRegressor на тестовой подвыборке: 1.2620493861319557\n"]}],"source":["vr = VotingRegressor(estimators=[('SVR', SVR(C=1, \n","                                             gamma='scale', \n","                                             kernel='rbf')),\n","                                               ('DecisionTreeRegressor', DecisionTreeRegressor(max_depth=2)),\n","                                               ('RandomForestRegressor', RandomForestRegressor(random_state=21, \n","                                                                                               max_depth=5, \n","                                                                                               n_estimators=100, \n","                                                                                               n_jobs=-1))],\n","                                   weights=[1, 1, 2],\n","                                   n_jobs=-1)\n","vr.fit(X_train, y_train)\n","print('RMSE VotingRegressor на тестовой подвыборке:', math.sqrt(mean_squared_error(y_test, vr.predict(X_test))))"]},{"cell_type":"markdown","id":"c97eefc0","metadata":{"id":"c97eefc0"},"source":["### BaggingRegressor"]},{"cell_type":"code","execution_count":null,"id":"e6afb2f5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e6afb2f5","outputId":"cff59260-7ef4-4675-f582-79906c5249fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["n_estimators: 1, RMSE is 1.3103631554731459\n","n_estimators: 2, RMSE is 1.3057079424180533\n","n_estimators: 5, RMSE is 1.2975045265046439\n","n_estimators: 10, RMSE is 1.2959717522793626\n","Best n_estimators: 10, RMSE is 1.2959717522793626\n"]}],"source":["best_RMSE = np.inf\n","best_n_estimators = 0\n","for n_estimators in (1, 2, 5, 10):\n","    br = BaggingRegressor(base_estimator=SVR(C=1, gamma='scale', kernel='rbf'), \n","                          n_estimators=n_estimators, \n","                          random_state=21, \n","                          n_jobs=-1)\n","    RMSE = math.sqrt(abs(cross_val_score(br, X_train, y_train, cv=5, scoring='neg_mean_squared_error').mean()))\n","    print(f'n_estimators: {n_estimators}, RMSE is {RMSE}')\n","    if RMSE < best_RMSE:\n","        best_RMSE = RMSE\n","        best_n_estimators = n_estimators\n","\n","print(f'Best n_estimators: {best_n_estimators}, RMSE is {best_RMSE}')"]},{"cell_type":"code","execution_count":null,"id":"ece4cb36","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ece4cb36","outputId":"b0cdbc4a-346a-4826-ebfe-090108e228e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE BaggingRegressor на тестовой подвыборке: 1.2879614065248797\n"]}],"source":["br = BaggingRegressor(base_estimator=SVR(C=1, gamma='scale', kernel='rbf'), \n","                      n_estimators=10, \n","                      random_state=21, \n","                      n_jobs=-1)\n","br.fit(X_train, y_train)\n","print('RMSE BaggingRegressor на тестовой подвыборке:', math.sqrt(mean_squared_error(y_test, br.predict(X_test))))"]},{"cell_type":"markdown","id":"9ac0a4a6","metadata":{"id":"9ac0a4a6"},"source":["### StackingRegressor"]},{"cell_type":"code","execution_count":null,"id":"4d816629","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4d816629","outputId":"113973d4-08ef-4e3d-b204-5b22652503ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Best passthrough: False, RMSE is 1.1762972489119579\n"]}],"source":["best_RMSE = np.inf\n","best_passthrough = True\n","for passthrough in [True, False]:\n","    sr = StackingRegressor(estimators=[('SVR', SVR(C=1, gamma='scale', kernel='rbf')),\n","                                       ('DecisionTreeRegressor', DecisionTreeRegressor(max_depth=2)),\n","                                       ('RandomForestRegressor', RandomForestRegressor(random_state=21, \n","                                                                                             max_depth=10,\n","                                                                                             max_features=50,\n","                                                                                             n_estimators=100, \n","                                                                                             n_jobs=-1))],\n","                           final_estimator=LinearRegression(),\n","                           cv=5, \n","                           passthrough=passthrough, n_jobs=-1)\n","    sr.fit(X_train, y_train)\n","    RMSE = math.sqrt(mean_squared_error(y_train, sr.predict(X_train)))\n","    if RMSE < best_RMSE:\n","        best_RMSE = RMSE\n","        best_passthrough = passthrough\n","\n","print(f'Best passthrough: {best_passthrough}, RMSE is {best_RMSE}')"]},{"cell_type":"code","execution_count":null,"id":"d9956749","metadata":{"id":"d9956749","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0826f885-c941-4f19-c536-11d354489391"},"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE StackingRegressor на тестовой подвыборке: 1.2390990288653385\n"]}],"source":["sr = StackingRegressor(estimators=[('SVR', SVR(C=1, gamma='scale', kernel='rbf')),\n","                                   ('DecisionTreeRegressor', DecisionTreeRegressor(max_depth=2)),\n","                                   ('RandomForestRegressor', RandomForestRegressor(random_state=21, \n","                                                                                   max_depth=5, \n","                                                                                   n_estimators=100, \n","                                                                                   n_jobs=-1))],\n","                       final_estimator=LinearRegression(),\n","                       passthrough=True, \n","                       n_jobs=-1)\n","sr.fit(X_train, y_train)\n","print('RMSE StackingRegressor на тестовой подвыборке:', math.sqrt(mean_squared_error(y_test, sr.predict(X_test))))"]},{"cell_type":"markdown","id":"fbf291f0","metadata":{"id":"fbf291f0"},"source":["### Наивный регрессор"]},{"cell_type":"code","execution_count":null,"id":"c0429437","metadata":{"id":"c0429437","colab":{"base_uri":"https://localhost:8080/"},"outputId":"74c09f5c-0168-40ed-b6e6-5abb0b419b93"},"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE наивного регрессора на тестовой подвыборке: 1.2858057380411216\n"]}],"source":["y_pred = np.full(len(y_test), y_train.mean())\n","print(f'RMSE наивного регрессора на тестовой подвыборке: {math.sqrt(mean_squared_error(y_test, y_pred))}')"]},{"cell_type":"markdown","id":"129c3b3f","metadata":{"id":"129c3b3f"},"source":["### Лучший регрессор\n","\n","StackingRegressor с параметрами {estimators=\n","\n","[('SVR', SVR(C=1, gamma='scale', kernel='rbf')),\n","\n","  ('DecisionTreeRegressor', DecisionTreeRegressor(max_depth=2)),\n","\n","  ('RandomForestRegressor', RandomForestRegressor(random_state=21,       max_depth=5,                                                                  n_estimators=100,                                                               n_jobs=-1))],\n","                       \n","final_estimator=LinearRegression(),\n","\n","passthrough=True, \n","\n","n_jobs=-1},\n","\n","и RMSE = 1.2390990288653385"]},{"cell_type":"markdown","id":"a5b57f65","metadata":{"id":"a5b57f65"},"source":["## Классификация 6 классов"]},{"cell_type":"code","execution_count":null,"id":"84b0c891","metadata":{"id":"84b0c891"},"outputs":[],"source":["X = df.drop(columns=['rating'])\n","y = df['rating'].round()"]},{"cell_type":"code","execution_count":null,"id":"e1206da2","metadata":{"id":"e1206da2"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)"]},{"cell_type":"code","execution_count":null,"id":"cd76f3b8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cd76f3b8","outputId":"2d5f5c69-92f0-410d-e0ba-9bdd83d786a0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0    0.080909\n","1.0    0.008945\n","2.0    0.035458\n","3.0    0.079378\n","4.0    0.666129\n","5.0    0.129180\n","Name: rating, dtype: float64"]},"metadata":{},"execution_count":15}],"source":["y_train.value_counts(normalize=True).sort_index()"]},{"cell_type":"code","execution_count":null,"id":"2af31162","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2af31162","outputId":"5ed7eecd-87ef-4655-f8e5-40ff9dc5c097"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0    0.080889\n","1.0    0.009024\n","2.0    0.035450\n","3.0    0.079278\n","4.0    0.666130\n","5.0    0.129230\n","Name: rating, dtype: float64"]},"metadata":{},"execution_count":14}],"source":["y_test.value_counts(normalize=True).sort_index()"]},{"cell_type":"markdown","id":"478278d0","metadata":{"id":"478278d0"},"source":["### LogisticRegression"]},{"cell_type":"code","execution_count":null,"id":"f17911da","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f17911da","outputId":"f84d7ea7-70e1-498c-ef17-e66d14839421"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'C': 1,\n","  'fit_intercept': True,\n","  'l1_ratio': 0.5,\n","  'penalty': 'l1',\n","  'solver': 'saga'},\n"," 0.7975662577896607)"]},"metadata":{},"execution_count":48}],"source":["param_grid = {'penalty': ('l1', 'l2', 'elasticnet', 'none'),\n","              'C': (0.1, 1, 10),\n","              'solver': ('newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'),\n","              'l1_ratio': [0.5],\n","              'fit_intercept': (True, False)}\n","\n","log_reg = GridSearchCV(estimator=LogisticRegression(random_state=21, n_jobs=-1),\n","                       param_grid=param_grid,\n","                       cv=5,\n","                       n_jobs=-1)\n","log_reg.fit(X_train, y_train)\n","log_reg.best_params_, log_reg.best_score_"]},{"cell_type":"code","execution_count":null,"id":"d8c72410","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d8c72410","outputId":"9ebee026-c458-4c73-d270-d22dca62e84e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy LogisticRegression на тесте: 0.7995488237189816\n"]}],"source":["print('Accuracy LogisticRegression на тестовой подвыборке:', accuracy_score(y_test, log_reg.best_estimator_.predict(X_test)))"]},{"cell_type":"markdown","id":"f15e2679","metadata":{"id":"f15e2679"},"source":["### DecisionTreeClassifier"]},{"cell_type":"code","execution_count":null,"id":"eb8ad242","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eb8ad242","outputId":"10db4241-5829-4076-bd8f-34766b5dbf6a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'max_depth': 3}, 0.6699171560426527)"]},"metadata":{},"execution_count":34}],"source":["param_grid = {'max_depth' : range(1, 100)}\n","dt_clf = GridSearchCV(estimator=DecisionTreeClassifier(), \n","                      param_grid=param_grid,\n","                      n_jobs=-1,\n","                      cv=5)\n","dt_clf.fit(X_train, y_train)\n","dt_clf.best_params_, dt_clf.best_score_"]},{"cell_type":"code","execution_count":null,"id":"b6a96ec6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b6a96ec6","outputId":"e745d425-56a7-49a6-bfc6-21cfa6f505b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy DecisionTreeClassifier на тестовой подвыборке: 0.6680631646793426\n"]}],"source":["print('Accuracy DecisionTreeClassifier на тестовой подвыборке:', accuracy_score(y_test, dt_clf.best_estimator_.predict(X_test)))"]},{"cell_type":"markdown","id":"27070937","metadata":{"id":"27070937"},"source":["### RandomForestClassifier"]},{"cell_type":"code","execution_count":null,"id":"2aa734c7","metadata":{"id":"2aa734c7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c96bd35f-d045-4eda-bed5-6d56fad11828"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'max_depth': 20, 'n_estimators': 70}, 0.6690308065715229)"]},"metadata":{},"execution_count":21}],"source":["param_grid = {'n_estimators' : range(10, 101, 10),\n","              'max_depth' : (1, 2, 5, 10, 15, 20)}\n","rf_clf = GridSearchCV(estimator=RandomForestClassifier(random_state=21),\n","                      param_grid=param_grid, \n","                      cv=5, \n","                      n_jobs=-1)\n","rf_clf.fit(X_train, y_train)\n","rf_clf.best_params_, rf_clf.best_score_"]},{"cell_type":"code","execution_count":null,"id":"de4cf9a3","metadata":{"id":"de4cf9a3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d97c8ea3-8de6-47e5-ed95-3dfbf7150b3e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy RandomForestClassifier на тестовой подвыборке: 0.6677408959071865\n"]}],"source":["print('Accuracy RandomForestClassifier на тестовой подвыборке:', accuracy_score(y_test, rf_clf.best_estimator_.predict(X_test)))"]},{"cell_type":"markdown","id":"2305b8ad","metadata":{"id":"2305b8ad"},"source":["### SVC"]},{"cell_type":"code","execution_count":null,"id":"4a8c94bc","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4a8c94bc","outputId":"4985d1c9-c8f6-4c83-b3c8-78f8774b9d00"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}, 0.7977274506231241)"]},"metadata":{},"execution_count":30}],"source":["param_grid = {'kernel': ('poly', 'rbf', 'sigmoid'),\n","              'gamma': ('scale', 'auto'),\n","              'C': (0.1, 1, 10)}\n","svc = GridSearchCV(estimator=SVC(),\n","                      param_grid=param_grid, \n","                      cv=5)\n","svc.fit(X_train, y_train)\n","svc.best_params_, svc.best_score_"]},{"cell_type":"code","execution_count":null,"id":"c67720c9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c67720c9","outputId":"4ab03ffc-3429-4972-97b5-14aade4c2b24"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy SVC на тестовой подвыборке: 0.7966484047695779\n"]}],"source":["print('Accuracy SVC на тестовой подвыборке:', accuracy_score(y_test, svc.best_estimator_.predict(X_test)))"]},{"cell_type":"markdown","id":"37ed68b7","metadata":{"id":"37ed68b7"},"source":["### VotingClassifier"]},{"cell_type":"code","execution_count":null,"id":"1a2567fd","metadata":{"id":"1a2567fd","colab":{"base_uri":"https://localhost:8080/"},"outputId":"81ba1da6-0c79-461c-8618-5faa4ef61fa6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Best params: {'voting': 'hard', 'weights': [1, 2, 1]}, accuracy is 0.6715288895038231\n"]}],"source":["best_accuracy = 0\n","best_params = 0\n","for voting in ('hard', 'soft'):\n","    for weight_1 in range(1, 3):\n","        for weight_2 in range(1, 3):\n","            for weight_3 in range(1, 3):\n","                vc = VotingClassifier(estimators=[('SVC', SVC(C=1, \n","                                                              gamma='scale', \n","                                                              kernel='rbf')),\n","                                                  ('LogisticRegression', LogisticRegression(C=1,\n","                                                                                            fit_intercept=True,\n","                                                                                            l1_ratio=0.5,\n","                                                                                            penalty='l1',\n","                                                                                            solver='saga')),\n","                                                  ('RandomForestClassifier', RandomForestClassifier(random_state=21, \n","                                                                                                    max_depth=15, \n","                                                                                                    n_estimators=100, \n","                                                                                                    n_jobs=-1))],\n","                                      weights=[weight_1, weight_2, weight_3],\n","                                      n_jobs=-1)\n","                accuracy = cross_val_score(vc, X_train, y_train, cv=5).mean()\n","                if accuracy > best_accuracy:\n","                    best_accuracy = accuracy\n","                    best_params = {'voting': voting, 'weights': [weight_1, weight_2, weight_3]}\n","\n","\n","print(f'Best params: {best_params}, accuracy is {best_accuracy}')"]},{"cell_type":"code","execution_count":null,"id":"5afaf844","metadata":{"id":"5afaf844","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fe152ad7-c43a-4f02-dc90-a9ac79ad608f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy VotingClassifier на тестовой подвыборке: 0.6696745085401224\n"]}],"source":["vc = VotingClassifier(estimators=[('SVC', SVC(C=1,\n","                                              gamma='scale',\n","                                              kernel='rbf')),\n","                                  ('LogisticRegression', LogisticRegression(C=1,\n","                                                                            fit_intercept=True,\n","                                                                            l1_ratio=0.5,\n","                                                                            penalty='l1',\n","                                                                            solver='saga')),\n","                                  ('RandomForestClassifier', RandomForestClassifier(random_state=21,\n","                                                                                    max_depth=15,\n","                                                                                    n_estimators=100, \n","                                                                                    n_jobs=-1))],\n","                      weights=[1, 2, 2],\n","                      voting='hard',\n","                      n_jobs=-1)\n","vc.fit(X_train, y_train)\n","print('Accuracy VotingClassifier на тестовой подвыборке:', accuracy_score(y_test, vc.predict(X_test)))"]},{"cell_type":"markdown","id":"0da181b4","metadata":{"id":"0da181b4"},"source":["### BaggingClassifier"]},{"cell_type":"code","execution_count":null,"id":"7bc5c33f","metadata":{"id":"7bc5c33f","colab":{"base_uri":"https://localhost:8080/"},"outputId":"be6a69ab-f548-4b79-fed1-bac62c33f002"},"outputs":[{"output_type":"stream","name":"stdout","text":["Best n_estimators: 2, accuracy is 0.6708036354294248\n"]}],"source":["best_accuracy = 0\n","best_n_estimators = 0\n","for n_estimators in (1, 2, 5, 10):\n","    bc = BaggingClassifier(base_estimator=SVC(C=1, gamma='scale', kernel='rbf'), \n","                           n_estimators=n_estimators, \n","                           random_state=21, \n","                           n_jobs=-1)\n","    accuracy = cross_val_score(bc, X_train, y_train, cv=5).mean()\n","    if accuracy > best_accuracy:\n","        best_accuracy = accuracy\n","        best_n_estimators = n_estimators\n","\n","print(f'Best n_estimators: {best_n_estimators}, accuracy is {best_accuracy}')"]},{"cell_type":"code","execution_count":null,"id":"644fb2d4","metadata":{"id":"644fb2d4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"709922b9-3f82-43dd-eef9-26394486a5a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy BaggingClassifier на тестовой подвыборке: 0.6664518208185627\n"]}],"source":["bc = BaggingClassifier(base_estimator=SVC(C=1, gamma='scale', kernel='rbf'), \n","                       n_estimators=2, \n","                       random_state=21, \n","                       n_jobs=-1)\n","bc.fit(X_train, y_train)\n","print('Accuracy BaggingClassifier на тестовой подвыборке:', accuracy_score(y_test, bc.predict(X_test)))"]},{"cell_type":"markdown","id":"39b14c6d","metadata":{"id":"39b14c6d"},"source":["### Наивный классификатор"]},{"cell_type":"code","execution_count":null,"id":"f5fa42c5","metadata":{"id":"f5fa42c5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b320f16a-b416-43d7-fe99-2aeb15a5247c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy наивного регрессора на тестовой подвыборке 0.6661295520464067\n"]}],"source":["y_pred = np.full(len(y_test), y_train.mode())\n","print(f'Accuracy наивного регрессора на тестовой подвыборке {accuracy_score(y_test, y_pred)}')"]},{"cell_type":"markdown","id":"bbe03a64","metadata":{"id":"bbe03a64"},"source":["### Лучший классификатор"]},{"cell_type":"code","execution_count":null,"id":"0c59a084","metadata":{"id":"0c59a084"},"outputs":[],"source":["print(\"SVC с параметрами {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}, Accuracy = 0.6707474226804123\")"]},{"cell_type":"markdown","id":"dbd3f330","metadata":{"id":"dbd3f330"},"source":["## Классификация 3 классов (хорошо/средне/плохо)"]},{"cell_type":"code","execution_count":null,"id":"d619d554","metadata":{"id":"d619d554"},"outputs":[],"source":["def binarize(y):\n","    if y in (0, 1):\n","        return 'bad'\n","    if y in (2, 3):\n","        return 'so-so'\n","    return 'great'"]},{"cell_type":"code","execution_count":null,"id":"23d0eca4","metadata":{"id":"23d0eca4"},"outputs":[],"source":["X = df.drop(columns=['rating'])\n","y = df['rating'].round().apply(binarize)"]},{"cell_type":"code","execution_count":null,"id":"a95c4ad1","metadata":{"id":"a95c4ad1"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)"]},{"cell_type":"code","execution_count":null,"id":"c1065c14","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c1065c14","outputId":"edff574d-e5b9-4c55-8787-af3518209477"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["bad      0.089854\n","great    0.795310\n","so-so    0.114836\n","Name: rating, dtype: float64"]},"metadata":{},"execution_count":16}],"source":["y_train.value_counts(normalize=True).sort_index()"]},{"cell_type":"code","execution_count":null,"id":"e71663ad","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e71663ad","outputId":"84a781e1-e8a2-43d7-cd7d-c97118e765e4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["bad      0.089913\n","great    0.795359\n","so-so    0.114728\n","Name: rating, dtype: float64"]},"metadata":{},"execution_count":17}],"source":["y_test.value_counts(normalize=True).sort_index()"]},{"cell_type":"markdown","id":"e731016c","metadata":{"id":"e731016c"},"source":["### LogisticRegression"]},{"cell_type":"code","execution_count":null,"id":"15fb210f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"15fb210f","outputId":"0899d911-ed9c-4401-c649-f660011e6642"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'C': 1,\n","  'fit_intercept': True,\n","  'l1_ratio': 0.5,\n","  'penalty': 'l1',\n","  'solver': 'saga'},\n"," 0.7975662577896607)"]},"metadata":{},"execution_count":27}],"source":["param_grid = {'penalty': ('l1', 'l2', 'elasticnet', 'none'),\n","              'C': (0.1, 1, 10),\n","              'solver': ('newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'),\n","              'l1_ratio': [0.5],\n","              'fit_intercept': (True, False)}\n","\n","log_reg = GridSearchCV(estimator=LogisticRegression(random_state=21, n_jobs=-1),\n","                       param_grid=param_grid,\n","                       cv=5,\n","                       n_jobs=-1)\n","log_reg.fit(X_train, y_train)\n","log_reg.best_params_, log_reg.best_score_"]},{"cell_type":"code","execution_count":null,"id":"6319cdde","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6319cdde","outputId":"79530756-7c9d-4a85-b469-33b2346d06a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy LogisticRegression на тестовой подвыборке: 0.7995488237189816\n"]}],"source":["print('Accuracy LogisticRegression на тестовой подвыборке:', accuracy_score(y_test, log_reg.best_estimator_.predict(X_test)))"]},{"cell_type":"markdown","id":"677083f6","metadata":{"id":"677083f6"},"source":["### DecisionTreeClassifier"]},{"cell_type":"code","execution_count":null,"id":"2e27d0b9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2e27d0b9","outputId":"1f20cbaf-026a-4d9d-88d6-5d6cfc0399c1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'max_depth': 1}, 0.797405097435108)"]},"metadata":{},"execution_count":39}],"source":["param_grid = {'max_depth' : range(1, 100)}\n","dt_clf = GridSearchCV(estimator=DecisionTreeClassifier(), \n","                      param_grid=param_grid,\n","                      n_jobs=-1,\n","                      cv=5)\n","dt_clf.fit(X_train, y_train)\n","dt_clf.best_params_, dt_clf.best_score_"]},{"cell_type":"code","execution_count":null,"id":"cdbfa1e7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cdbfa1e7","outputId":"50cafb7e-56c7-4dc5-d15d-9494b7c90af9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy DecisionTreeClassifier на тестовой подвыборке: 0.7966484047695779\n"]}],"source":["print('Accuracy DecisionTreeClassifier на тестовой подвыборке:', accuracy_score(y_test, dt_clf.best_estimator_.predict(X_test)))"]},{"cell_type":"markdown","id":"b79d2e17","metadata":{"id":"b79d2e17"},"source":["### RandomForestClassifier"]},{"cell_type":"code","execution_count":null,"id":"347134dd","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"347134dd","outputId":"b135a860-0557-43d5-dcc1-131fad20d06f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'max_depth': 20, 'n_estimators': 70}, 0.7965991982256121)"]},"metadata":{},"execution_count":41}],"source":["param_grid = {'n_estimators' : range(10, 101, 10),\n","              'max_depth' : (1, 2, 5, 10, 15, 20)}\n","rf_clf = GridSearchCV(estimator=RandomForestClassifier(random_state=21),\n","                      param_grid=param_grid, \n","                      cv=5, \n","                      n_jobs=-1)\n","rf_clf.fit(X_train, y_train)\n","rf_clf.best_params_, rf_clf.best_score_"]},{"cell_type":"code","execution_count":null,"id":"13dcbc66","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"13dcbc66","outputId":"bdfe02c6-ea50-499e-fde5-c2bd737ded04"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy RandomForestClassifier на тестовой подвыборке: 0.7969706735417338\n"]}],"source":["print('Accuracy RandomForestClassifier на тестовой подвыборке:', accuracy_score(y_test, rf_clf.best_estimator_.predict(X_test)))"]},{"cell_type":"markdown","id":"0c620cb2","metadata":{"id":"0c620cb2"},"source":["### SVC"]},{"cell_type":"code","execution_count":null,"id":"027be226","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"027be226","outputId":"2406a3fd-0d54-4cb1-a669-453255f00361"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}, 0.7977274506231241)"]},"metadata":{},"execution_count":20}],"source":["param_grid = {'kernel': ('poly', 'rbf', 'sigmoid'),\n","              'gamma': ('scale', 'auto'),\n","              'C': (0.1, 1, 10)}\n","svc = GridSearchCV(estimator=SVC(),\n","                      param_grid=param_grid, \n","                      cv=5)\n","svc.fit(X_train, y_train)\n","svc.best_params_, svc.best_score_"]},{"cell_type":"code","execution_count":null,"id":"b44555fe","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b44555fe","outputId":"7d51899d-e7ba-486a-fe24-f37b79083062"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy SVC на тестовой подвыборке: 0.7966484047695779\n"]}],"source":["print('Accuracy SVC на тестовой подвыборке:', accuracy_score(y_test, svc.best_estimator_.predict(X_test)))"]},{"cell_type":"markdown","id":"3f2ed732","metadata":{"id":"3f2ed732"},"source":["### GradientBoostingClassifier"]},{"cell_type":"code","execution_count":null,"id":"66709bfb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"66709bfb","outputId":"d6694aca-e675-40bb-b6b3-ab61d5f5a10f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'max_depth': 2, 'n_estimators': 80}, 0.7971633244243682)"]},"metadata":{},"execution_count":47}],"source":["param_grid = {'n_estimators' : range(10, 101, 10),\n","              'max_depth' : (1, 2, 5, 10, 15, 20)}\n","gb_clf = GridSearchCV(estimator=GradientBoostingClassifier(random_state=21),\n","                      param_grid=param_grid, \n","                      cv=5,\n","                      n_jobs=-1)\n","gb_clf.fit(X_train, y_train)\n","gb_clf.best_params_, gb_clf.best_score_"]},{"cell_type":"code","execution_count":null,"id":"d9f838d8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d9f838d8","outputId":"d68d9441-1bbb-4395-b998-480f97edd971"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy GradientBoostingClassifier на тестовой подвыборке: 0.7976152110860457\n"]}],"source":["print('Accuracy GradientBoostingClassifier на тестовой подвыборке:', accuracy_score(y_test, gb_clf.best_estimator_.predict(X_test)))"]},{"cell_type":"markdown","id":"1eee3c6a","metadata":{"id":"1eee3c6a"},"source":["### VotingClassifier"]},{"cell_type":"code","execution_count":null,"id":"c9809a2d","metadata":{"id":"c9809a2d"},"outputs":[],"source":["best_accuracy = 0\n","best_params = 0\n","for voting in ('hard', 'soft'):\n","    for weight_1 in range(1, 3):\n","        for weight_2 in range(1, 3):\n","            for weight_3 in range(1, 3):\n","                vc = VotingClassifier(estimators=[('SVC', SVC(C=1, \n","                                                              gamma='scale', \n","                                                              kernel='rbf')),\n","                                                  ('LogisticRegression', LogisticRegression(C=1,\n","                                                                                            fit_intercept=True,\n","                                                                                            l1_ratio=0.5,\n","                                                                                            penalty='l1',\n","                                                                                            solver='saga')),\n","                                                  ('RandomForestClassifier', RandomForestClassifier(random_state=21, \n","                                                                                                    max_depth=15, \n","                                                                                                    n_estimators=100, \n","                                                                                                    n_jobs=-1))],\n","                                      weights=[weight_1, weight_2, weight_3],\n","                                      n_jobs=-1)\n","                accuracy = cross_val_score(vc, X_train, y_train, cv=5).mean()\n","                if accuracy > best_accuracy:\n","                    best_accuracy = accuracy\n","                    best_params = {'voting': voting, 'weights': [weight_1, weight_2, weight_3]}"]},{"cell_type":"code","execution_count":null,"id":"39107862","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"39107862","outputId":"6e035b25-8694-4c8f-f6a3-162c2b6e4bc2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy VotingClassifier на тестовой подвыборке: 0.7969706735417338\n"]}],"source":["vc = VotingClassifier(estimators=[('SVC', SVC(C=1,\n","                                              gamma='scale',\n","                                              kernel='rbf')),\n","                                  ('LogisticRegression', LogisticRegression(C=1,\n","                                                                            fit_intercept=True,\n","                                                                            l1_ratio=0.5,\n","                                                                            penalty='l1',\n","                                                                            solver='saga')),\n","                                  ('RandomForestClassifier', RandomForestClassifier(random_state=21,\n","                                                                                    max_depth=15, \n","                                                                                    n_estimators=100, \n","                                                                                    n_jobs=-1))],\n","                                      weights=[2, 1, 1],\n","                                      n_jobs=-1)\n","vc.fit(X_train, y_train)\n","print('Accuracy VotingClassifier на тестовой подвыборке:', accuracy_score(y_test, vc.predict(X_test)))"]},{"cell_type":"markdown","id":"e7c811ea","metadata":{"id":"e7c811ea"},"source":["### BaggingClassifier"]},{"cell_type":"code","execution_count":null,"id":"44e5b412","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"44e5b412","outputId":"549f4742-6747-4eca-82a9-d92227aaef87"},"outputs":[{"output_type":"stream","name":"stdout","text":["Best n_estimators: 5, accuracy is 0.7978886759354982\n"]}],"source":["best_accuracy = 0\n","best_n_estimators = 0\n","for n_estimators in (1, 2, 5, 10):\n","    bc = BaggingClassifier(base_estimator=SVC(C=1, gamma='scale', kernel='rbf'), \n","                           n_estimators=n_estimators, \n","                           random_state=21, \n","                           n_jobs=-1)\n","    accuracy = cross_val_score(bc, X_train, y_train, cv=5).mean()\n","    if accuracy > best_accuracy:\n","        best_accuracy = accuracy\n","        best_n_estimators = n_estimators\n","\n","print(f'Best n_estimators: {best_n_estimators}, accuracy is {best_accuracy}')"]},{"cell_type":"code","execution_count":null,"id":"3d8d9b07","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3d8d9b07","outputId":"f6e62a65-b0a1-4853-f889-32847bba58bd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy BaggingClassifier на тестовой подвыборке: 0.7979374798582017\n"]}],"source":["bc = BaggingClassifier(base_estimator=SVC(C=1, gamma='scale', kernel='rbf'),\n","                       n_estimators=10,\n","                       random_state=21,\n","                       n_jobs=-1)\n","bc.fit(X_train, y_train)\n","print('Accuracy BaggingClassifier на тестовой подвыборке:', accuracy_score(y_test, bc.predict(X_test)))"]},{"cell_type":"markdown","id":"57cd23e7","metadata":{"id":"57cd23e7"},"source":["### StackingClassifier"]},{"cell_type":"code","execution_count":null,"id":"12c99676","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"12c99676","outputId":"e8255efe-40a1-4722-8e8d-6b49a4c53661"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Best passthrough: True, accuracy is 0.7069062777016681\n"]}],"source":["best_accuracy = 0\n","best_passthrough = True\n","for passthrough in [True, False]:\n","    sc = StackingClassifier(estimators=[('SVC', SVC(C=1,\n","                                                    gamma='scale',\n","                                                    kernel='rbf')),\n","                                        ('LogisticRegression', LogisticRegression(C=1,\n","                                                                                  fit_intercept=True,\n","                                                                                  l1_ratio=0.5,\n","                                                                                  penalty='l1',\n","                                                                                  solver='saga')),\n","                                        ('RandomForestClassifier', RandomForestClassifier(random_state=21,\n","                                                                                          max_depth=15,\n","                                                                                          n_estimators=100,\n","                                                                                          n_jobs=-1))],\n","                            final_estimator=DecisionTreeClassifier(),\n","                            cv=5,\n","                            passthrough=passthrough, \n","                            n_jobs=-1)\n","    sc.fit(X_train, y_train)\n","    accuracy = accuracy_score(y_train, sc.predict(X_train))\n","    if accuracy > best_accuracy:\n","        best_accuracy = accuracy\n","        best_passthrough = passthrough\n","\n","print(f'Best passthrough: {best_passthrough}, accuracy is {best_accuracy}')"]},{"cell_type":"code","execution_count":null,"id":"b67948ce","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b67948ce","outputId":"482347f6-66de-4c9b-9069-fb4068f6b62f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy StackingClassifier на тестовой подвыборке: 0.6674186271350306\n"]}],"source":["sc = StackingClassifier(estimators=[('SVC', SVC(C=1,\n","                                                gamma='scale',\n","                                                kernel='rbf')),\n","                                    ('LogisticRegression', LogisticRegression(C=1,\n","                                                                              fit_intercept=True,\n","                                                                              l1_ratio=0.5,\n","                                                                              penalty='l1',\n","                                                                              solver='saga')),\n","                                    ('RandomForestClassifier', RandomForestClassifier(random_state=21,\n","                                                                                      max_depth=15, \n","                                                                                      n_estimators=100, \n","                                                                                      n_jobs=-1))],\n","                      final_estimator=DecisionTreeClassifier(),\n","                      cv=5,\n","                      passthrough=True,\n","                      n_jobs=-1)\n","sc.fit(X_train, y_train)\n","print('Accuracy StackingClassifier на тестовой подвыборке:', accuracy_score(y_test, sc.predict(X_test)))"]},{"cell_type":"markdown","id":"d7efab1e","metadata":{"id":"d7efab1e"},"source":["### Наивный классификатор"]},{"cell_type":"code","execution_count":null,"id":"324b6ce9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"324b6ce9","outputId":"5f258c26-81e5-4c5b-c551-4f6d9e4ad7e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy наивного регрессора на тестовой подвыборке 0.7953593296809539\n"]}],"source":["y_pred = np.full(len(y_test), y_train.mode())\n","print(f'Accuracy наивного регрессора на тестовой подвыборке {accuracy_score(y_test, y_pred)}')"]},{"cell_type":"markdown","id":"7b7f8534","metadata":{"id":"7b7f8534"},"source":["### Лучший классификатор"]},{"cell_type":"code","execution_count":null,"id":"34084c99","metadata":{"id":"34084c99"},"outputs":[],"source":["print(\"LogisticRegression с параметрами {'C': 1, 'fit_intercept': True, 'l1_ratio': 0.5, 'penalty': 'l1', 'solver': 'saga'}, Accuracy = 0.7995488237189816\")"]},{"cell_type":"markdown","id":"df477004","metadata":{"id":"df477004"},"source":["### Выбор новой метрики"]},{"cell_type":"markdown","id":"fa2276d2","metadata":{"id":"fa2276d2"},"source":["Если спрогнозировать плохой рейтинг, который на самом деле окажется хорошим, то ничего особо страшного не произойдет, пользователь может ввести новый список продуктов и найти другой рецепт. \n","\n","Но если спрогнозировать хороший рейтинг, который на самом деле окажется плохим, то пользователь потратит время и продукты на приготовление блюда, которое будет невозможно есть.\n","\n","Поэтому метрику accuracy лучше заменим на precision (точность) и будем выбирать модель с самой высокой precision по классу great."]},{"cell_type":"markdown","id":"e3a41bc8","metadata":{"id":"e3a41bc8"},"source":["## Классификация 3 класса с метрикой precision по классу great"]},{"cell_type":"code","execution_count":null,"id":"b76ce369","metadata":{"id":"b76ce369"},"outputs":[],"source":["precision_great = make_scorer(precision_score, average='weighted')"]},{"cell_type":"markdown","id":"8af8ed2d","metadata":{"id":"8af8ed2d"},"source":["### LogisticRegression"]},{"cell_type":"code","execution_count":null,"id":"6abd2c60","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6abd2c60","outputId":"a7c0937d-c92a-4765-be0b-d5d5c14e0b67"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'C': 1,\n","  'fit_intercept': True,\n","  'l1_ratio': 0.5,\n","  'penalty': 'l2',\n","  'solver': 'newton-cg'},\n"," 0.7071846843884967)"]},"metadata":{},"execution_count":34}],"source":["param_grid = {'penalty': ('l1', 'l2', 'elasticnet', 'none'),\n","              'C': (0.1, 1, 10),\n","              'solver': ('newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'),\n","              'l1_ratio': [0.5],\n","              'fit_intercept': (True, False)}\n","\n","log_reg = GridSearchCV(estimator=LogisticRegression(random_state=21, n_jobs=-1),\n","                       param_grid=param_grid,\n","                       cv=5,\n","                       scoring=precision_great,\n","                       n_jobs=-1)\n","log_reg.fit(X_train, y_train)\n","log_reg.best_params_, log_reg.best_score_"]},{"cell_type":"code","execution_count":null,"id":"1f4c222d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1f4c222d","outputId":"73c9f422-3fdd-4f17-9351-e61eba6b7d13"},"outputs":[{"output_type":"stream","name":"stdout","text":["Precision LogisticRegression на тестовой подвыборке: 0.6947081142919056\n"]}],"source":["print('Precision LogisticRegression на тестовой подвыборке:', precision_score(y_test, log_reg.best_estimator_.predict(X_test), average='weighted'))"]},{"cell_type":"markdown","id":"3edbf740","metadata":{"id":"3edbf740"},"source":["### DecisionTreeClassifier"]},{"cell_type":"code","execution_count":null,"id":"5c5659f4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5c5659f4","outputId":"777ed913-95a8-4d29-c64f-aa65c0c6ad8c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'max_depth': 11}, 0.6980720970479933)"]},"metadata":{},"execution_count":36}],"source":["param_grid = {'max_depth' : range(1, 100)}\n","dt_clf = GridSearchCV(estimator=DecisionTreeClassifier(), \n","                      param_grid=param_grid,\n","                      n_jobs=-1,\n","                      scoring=precision_great,\n","                      cv=5)\n","dt_clf.fit(X_train, y_train)\n","dt_clf.best_params_, dt_clf.best_score_"]},{"cell_type":"code","execution_count":null,"id":"a6fe9472","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a6fe9472","outputId":"8453514a-c217-41a1-cbe7-dd5617710124"},"outputs":[{"output_type":"stream","name":"stdout","text":["Precision DecisionTreeClassifier на тестовой подвыборке: 0.6816601036107802\n"]}],"source":["print('Precision DecisionTreeClassifier на тестовой подвыборке:', precision_score(y_test, dt_clf.best_estimator_.predict(X_test), average='weighted'))"]},{"cell_type":"markdown","id":"ad77fedb","metadata":{"id":"ad77fedb"},"source":["### RandomForestClassifier"]},{"cell_type":"code","execution_count":null,"id":"beaa39b6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"beaa39b6","outputId":"e0a5ed7d-e574-441f-f38a-b65fc53a726e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'max_depth': 1, 'n_estimators': 20}, 0.7719903871505268)"]},"metadata":{},"execution_count":24}],"source":["param_grid = {'n_estimators' : range(10, 101, 10),\n","              'max_depth' : (1, 2, 5, 10, 15, 20)}\n","rf_clf = GridSearchCV(estimator=RandomForestClassifier(random_state=21, class_weight={'bad': 3.341875, 'great': 0.420196463654224, 'so-so': 3.115967365967366}),\n","                      param_grid=param_grid, \n","                      cv=5,\n","                      scoring=precision_great,                      \n","                      n_jobs=-1)\n","rf_clf.fit(X_train, y_train)\n","rf_clf.best_params_, rf_clf.best_score_"]},{"cell_type":"code","source":["print('Precision RandomForestClassifier на тестовой подвыборке:', precision_score(y_test, rf_clf.best_estimator_.predict(X_test), average='weighted'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cvN4_0uD-9kN","outputId":"b0809b8a-0f6f-456e-dc42-3eec40c61747"},"id":"cvN4_0uD-9kN","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision RandomForestClassifier на тестовой подвыборке: 0.8055181253962592\n"]}]},{"cell_type":"markdown","id":"c7850d81","metadata":{"id":"c7850d81"},"source":["### SVC"]},{"cell_type":"code","execution_count":null,"id":"761e74f9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"761e74f9","outputId":"fb40c4ab-84d8-4d04-a629-4a384bab8b74"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'C': 1, 'gamma': 'scale', 'kernel': 'poly'}, 0.6950420146203853)"]},"metadata":{},"execution_count":49}],"source":["param_grid = {'kernel': ('poly', 'rbf', 'sigmoid'),\n","              'gamma': ('scale', 'auto'),\n","              'C': (0.1, 1, 10)}\n","svc = GridSearchCV(estimator=SVC(),\n","                   param_grid=param_grid, \n","                   scoring=precision_great,\n","                   cv=5)\n","svc.fit(X_train, y_train)\n","svc.best_params_, svc.best_score_"]},{"cell_type":"code","execution_count":null,"id":"c26011e9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c26011e9","outputId":"d1bb03b0-459c-4c21-b05a-dd58c502948c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Precision SVC на тестовой подвыборке: 0.7042814396199809\n"]}],"source":["print('Precision SVC на тестовой подвыборке:', precision_score(y_test, svc.best_estimator_.predict(X_test), average='weighted'))"]},{"cell_type":"markdown","id":"e1307e33","metadata":{"id":"e1307e33"},"source":["### GradientBoostingClassifier"]},{"cell_type":"code","execution_count":null,"id":"812482ce","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"812482ce","outputId":"84f17d06-2cd2-4513-db69-9d07b1de85da"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'max_depth': 5, 'n_estimators': 40}, 0.7178448274446497)"]},"metadata":{},"execution_count":51}],"source":["param_grid = {'n_estimators' : range(10, 101, 10),\n","              'max_depth' : (1, 2, 5, 10, 15, 20)}\n","gb_clf = GridSearchCV(estimator=GradientBoostingClassifier(random_state=21),\n","                      param_grid=param_grid, \n","                      cv=5,\n","                      scoring=precision_great,\n","                      n_jobs=-1)\n","gb_clf.fit(X_train, y_train)\n","gb_clf.best_params_, gb_clf.best_score_"]},{"cell_type":"code","execution_count":null,"id":"5b848ba8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5b848ba8","outputId":"68c854be-5967-4982-cbec-3e800f33cb4d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Precision GradientBoostingClassifier на тестовой подвыборке: 0.7288408765276287\n"]}],"source":["print('Precision GradientBoostingClassifier на тестовой подвыборке:', precision_score(y_test, gb_clf.best_estimator_.predict(X_test), average='weighted'))"]},{"cell_type":"markdown","id":"50658dff","metadata":{"id":"50658dff"},"source":["### VotingClassifier"]},{"cell_type":"code","execution_count":null,"id":"c803f39d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c803f39d","outputId":"21f70105-98dc-47b2-d36d-3ca8af2c6260"},"outputs":[{"output_type":"stream","name":"stdout","text":["Best params: {'voting': 'hard', 'weights': [2, 2, 2]}, precision is 0.7406939676513888\n"]}],"source":["best_precision = 0\n","best_params = 0\n","for voting in ('hard', 'soft'):\n","    for weight_1 in range(1, 3):\n","        for weight_2 in range(1, 3):\n","            for weight_3 in range(1, 3):\n","                vc = VotingClassifier(estimators=[('SVC', SVC(C=1, \n","                                                              gamma='scale', \n","                                                              kernel='poly')),\n","                                                  ('LogisticRegression', LogisticRegression(C=1,\n","                                                                                            fit_intercept=True,\n","                                                                                            l1_ratio=0.5,\n","                                                                                            penalty='l2',\n","                                                                                            solver='newton-cg')),\n","                                                  ('DecisionTreeClassifier', DecisionTreeClassifier(max_depth=15))],\n","                                      voting=voting,\n","                                      weights=[weight_1, weight_2, weight_3],\n","                                      n_jobs=-1)\n","                precision = cross_val_score(vc, X_train, y_train, cv=5, scoring=precision_great).mean()\n","                if precision > best_precision:\n","                    best_precision = precision\n","                    best_params = {'voting': voting, 'weights': [weight_1, weight_2, weight_3]}\n","\n","\n","print(f'Best params: {best_params}, precision is {best_precision}')"]},{"cell_type":"code","execution_count":null,"id":"1f8640e1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1f8640e1","outputId":"8fde880b-1713-4fa7-d264-0993a8f30b56"},"outputs":[{"output_type":"stream","name":"stdout","text":["Precision VotingClassifier на тестовой подвыборке: 0.6767483080889463\n"]}],"source":["vc = VotingClassifier(estimators=[('SVC', SVC(C=1,\n","                                              gamma='scale',\n","                                              kernel='poly')),\n","                                  ('LogisticRegression', LogisticRegression(C=1,\n","                                                                            fit_intercept=True,\n","                                                                            l1_ratio=0.5,\n","                                                                            penalty='l2',\n","                                                                            solver='newton-cg')),\n","                                  ('DecisionTreeClassifier', DecisionTreeClassifier(max_depth=15))],\n","                      voting='hard',\n","                      weights=[1, 1, 2],\n","                      n_jobs=-1)\n","vc.fit(X_train, y_train)\n","print('Precision VotingClassifier на тестовой подвыборке:', precision_score(y_test, vc.predict(X_test), average='weighted'))"]},{"cell_type":"markdown","id":"cd8b3e88","metadata":{"id":"cd8b3e88"},"source":["### BaggingClassifier"]},{"cell_type":"code","execution_count":null,"id":"bc1784e0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bc1784e0","outputId":"e6bae463-8380-4938-9783-d9f9253f4060"},"outputs":[{"output_type":"stream","name":"stdout","text":["Best n_estimators: 10, precision is 0.6956374446992589\n"]}],"source":["best_precision = 0\n","best_n_estimators = 0\n","for n_estimators in (1, 2, 5, 10):\n","    bc = BaggingClassifier(base_estimator=SVC(C=1, gamma='scale', kernel='poly'), \n","                           n_estimators=n_estimators, \n","                           random_state=21, \n","                           n_jobs=-1)\n","    precision = cross_val_score(bc, X_train, y_train, cv=5, scoring=precision_great).mean()\n","    if precision > best_precision:\n","        best_precision = precision\n","        best_n_estimators = n_estimators\n","\n","print(f'Best n_estimators: {best_n_estimators}, precision is {best_precision}')"]},{"cell_type":"code","execution_count":null,"id":"dc637c03","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dc637c03","outputId":"2f381ddb-e86b-4ad2-ca2b-1ae3ab1a19f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Precision BaggingClassifier на тестовой подвыборке: 0.6981520834384348\n"]}],"source":["bc = BaggingClassifier(base_estimator=SVC(C=1, gamma='scale', kernel='poly'), \n","                           n_estimators=10, \n","                           random_state=21, \n","                           n_jobs=-1)\n","bc.fit(X_train, y_train)\n","print('Precision BaggingClassifier на тестовой подвыборке:', precision_score(y_test, bc.predict(X_test), average='weighted'))"]},{"cell_type":"markdown","id":"c7b5862d","metadata":{"id":"c7b5862d"},"source":["### StackingClassifier"]},{"cell_type":"code","execution_count":null,"id":"4e02265e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4e02265e","outputId":"1f2c1059-bb1b-445e-9e37-0898ff63cf31"},"outputs":[{"output_type":"stream","name":"stdout","text":["Best passthrough: True, precision is 0.8071643213412145\n"]}],"source":["best_precision = 0\n","best_passthrough = True\n","for passthrough in [True, False]:\n","    sc = StackingClassifier(estimators=[('SVC', SVC(C=1,\n","                                                    gamma='scale',\n","                                                    kernel='poly')),\n","                                        ('LogisticRegression', LogisticRegression(C=1,\n","                                                                                  fit_intercept=True,\n","                                                                                  l1_ratio=0.5,\n","                                                                                  penalty='l2',\n","                                                                                  solver='newton-cg')),\n","                                                  ('DecisionTreeClassifier', DecisionTreeClassifier(max_depth=15))],\n","                            final_estimator=RandomForestClassifier(random_state=21),\n","                            cv=5,\n","                            passthrough=passthrough, \n","                            n_jobs=-1)\n","    sc.fit(X_train, y_train)\n","    precision = precision_score(y_train, sc.predict(X_train), average='weighted')\n","    if precision > best_precision:\n","        best_precision = precision\n","        best_passthrough = passthrough\n","\n","print(f'Best passthrough: {best_passthrough}, precision is {best_precision}')"]},{"cell_type":"code","execution_count":null,"id":"ed6e9967","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ed6e9967","outputId":"f985fc2e-3e98-48bc-c8ac-189d9d6229fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Precision StackingClassifier на тестовой подвыборке: 0.682289457314377\n"]}],"source":["sc = StackingClassifier(estimators=[('SVC', SVC(C=1,\n","                                                gamma='scale',\n","                                                kernel='poly')),\n","                                    ('LogisticRegression', LogisticRegression(C=1,\n","                                                                              fit_intercept=True,\n","                                                                              l1_ratio=0.5,\n","                                                                              penalty='l2',\n","                                                                              solver='newton-cg')),\n","                                    ('DecisionTreeClassifier', DecisionTreeClassifier(max_depth=15))],\n","                        final_estimator=RandomForestClassifier(random_state=21),\n","                        cv=5,\n","                        passthrough=True, \n","                        n_jobs=-1)\n","sc.fit(X_train, y_train)\n","print('Precision StackingClassifier на тестовой подвыборке:', precision_score(y_test, sc.predict(X_test), average='weighted'))"]},{"cell_type":"markdown","id":"843aeacd","metadata":{"id":"843aeacd"},"source":["### Наивный классификатор"]},{"cell_type":"code","execution_count":null,"id":"38832d14","metadata":{"id":"38832d14","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5b5075e0-22e3-479f-e6ac-60d62ce6de07"},"outputs":[{"output_type":"stream","name":"stdout","text":["Precision наивного регрессора на тестовой подвыборке 0.6325964633105363\n"]}],"source":["y_pred = np.full(len(y_test), y_train.mode())\n","print(f'Precision наивного регрессора на тестовой подвыборке {precision_score(y_test, y_pred, average=\"weighted\")}')"]},{"cell_type":"markdown","id":"7d74ad97","metadata":{"id":"7d74ad97"},"source":["### Принятие решения о лучшей модели"]},{"cell_type":"markdown","id":"25751837","metadata":{"id":"25751837"},"source":["Лучший классификатор в данном случае оказался RandomForestClassifier (второй по качеству) с параметрами max_depth= 1, n_estimators= 20, class_weight={'bad': 3.341875, 'great': 0.420196463654224, 'so-so': 3.115967365967366}"]},{"cell_type":"code","source":["best_model = RandomForestClassifier(random_state=21, max_depth= 1, n_estimators= 20, class_weight={'bad': 3.341875, 'great': 0.420196463654224, 'so-so': 3.115967365967366})\n","best_model.fit(X_train, y_train)\n","precision_score(y_test, best_model.predict(X_test), average='weighted')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mn9oP-ohNCfE","outputId":"48e4b2ac-d3c4-41c0-ff75-6420e1ed2ee0"},"id":"Mn9oP-ohNCfE","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8055181253962592"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["dump(best_model, '/content/drive/MyDrive/Школа 21/DS_project 15 Создание прототипа рекомендательного сервиса рецептов/best_model.joblib')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SlyA6jFRNyq4","outputId":"089f2e21-00f5-454f-9981-d137164761c2"},"id":"SlyA6jFRNyq4","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/drive/MyDrive/Школа 21/DS_project 15 Создание прототипа рекомендательного сервиса рецептов/best_model.joblib']"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["best_model_1 = load('/content/drive/MyDrive/Школа 21/DS_project 15 Создание прототипа рекомендательного сервиса рецептов/best_model.joblib')\n","precision_score(y_test, best_model_1.predict(X_test), average='weighted')"],"metadata":{"id":"mCSIq7fOxn3b","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6436ffd2-2715-4113-ba56-2b5edf15430d"},"id":"mCSIq7fOxn3b","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8055181253962592"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","id":"3d6ea4d5","metadata":{"id":"3d6ea4d5"},"source":["# Пищевая ценность"]},{"cell_type":"code","source":["nutrients = pd.read_csv('/content/drive/MyDrive/Школа 21/DS_project 15 Создание прототипа рекомендательного сервиса рецептов/daily_rate_nutrients.csv')\n","nutrients"],"metadata":{"id":"W6AHPBDMhnlw","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"01de4e4c-5829-48c3-a453-8625133ac19a"},"id":"W6AHPBDMhnlw","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               nutrient   value                    nutrient_api\n","0                   Fat    38.0               Total lipid (fat)\n","1         Saturated fat    20.0    Fatty acids, total saturated\n","2           Cholesterol   300.0                     Cholesterol\n","3   Total carbohydrates   275.0     Carbohydrate, by difference\n","4                Sodium  2300.0                      Sodium, Na\n","5         Dietary Fiber    28.0            Fiber, total dietary\n","6               Protein    50.0                         Protein\n","7          Added sugars    50.0                   Sugars, added\n","8             Vitamin A   900.0                  Vitamin A, RAE\n","9             Vitamin C    90.0  Vitamin C, total ascorbic acid\n","10              Calcium  1300.0                     Calcium, Ca\n","11                 Iron    18.0                        Iron, Fe\n","12            Vitamin D    20.0             Vitamin D (D2 + D3)\n","13            Vitamin E    15.0    Vitamin E (alpha-tocopherol)\n","14            Vitamin K   120.0       Vitamin K (phylloquinone)\n","15              Thiamin     1.2                         Thiamin\n","16           Riboflavin     1.3                      Riboflavin\n","17               Niacin    16.0                          Niacin\n","18           Vitamin B6     1.7                     Vitamin B-6\n","19               Folate   400.0                     Folate, DFE\n","20          Vitamin B12     2.4                    Vitamin B-12\n","21               Biotin    30.0                          Biotin\n","22     Pantothenic acid     5.0                Pantothenic acid\n","23           Phosphorus  1250.0                   Phosphorus, P\n","24            Magnesium   420.0                   Magnesium, Mg\n","25                 Zinc    11.0                        Zinc, Zn\n","26             Selenium    55.0                    Selenium, Se\n","27               Copper     0.9                      Copper, Cu\n","28            Manganese     2.3                   Manganese, Mn\n","29           Molybdenum    45.0                  Molybdenum, Mo\n","30            Potassium  4700.0                    Potassium, K\n","31              Choline   550.0                  Choline, total"],"text/html":["\n","  <div id=\"df-29a25b68-0d73-448e-a8e7-efd3c51edc94\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>nutrient</th>\n","      <th>value</th>\n","      <th>nutrient_api</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Fat</td>\n","      <td>38.0</td>\n","      <td>Total lipid (fat)</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Saturated fat</td>\n","      <td>20.0</td>\n","      <td>Fatty acids, total saturated</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Cholesterol</td>\n","      <td>300.0</td>\n","      <td>Cholesterol</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Total carbohydrates</td>\n","      <td>275.0</td>\n","      <td>Carbohydrate, by difference</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sodium</td>\n","      <td>2300.0</td>\n","      <td>Sodium, Na</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Dietary Fiber</td>\n","      <td>28.0</td>\n","      <td>Fiber, total dietary</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Protein</td>\n","      <td>50.0</td>\n","      <td>Protein</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Added sugars</td>\n","      <td>50.0</td>\n","      <td>Sugars, added</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Vitamin A</td>\n","      <td>900.0</td>\n","      <td>Vitamin A, RAE</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Vitamin C</td>\n","      <td>90.0</td>\n","      <td>Vitamin C, total ascorbic acid</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Calcium</td>\n","      <td>1300.0</td>\n","      <td>Calcium, Ca</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Iron</td>\n","      <td>18.0</td>\n","      <td>Iron, Fe</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Vitamin D</td>\n","      <td>20.0</td>\n","      <td>Vitamin D (D2 + D3)</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Vitamin E</td>\n","      <td>15.0</td>\n","      <td>Vitamin E (alpha-tocopherol)</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>Vitamin K</td>\n","      <td>120.0</td>\n","      <td>Vitamin K (phylloquinone)</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>Thiamin</td>\n","      <td>1.2</td>\n","      <td>Thiamin</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>Riboflavin</td>\n","      <td>1.3</td>\n","      <td>Riboflavin</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>Niacin</td>\n","      <td>16.0</td>\n","      <td>Niacin</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>Vitamin B6</td>\n","      <td>1.7</td>\n","      <td>Vitamin B-6</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>Folate</td>\n","      <td>400.0</td>\n","      <td>Folate, DFE</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>Vitamin B12</td>\n","      <td>2.4</td>\n","      <td>Vitamin B-12</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>Biotin</td>\n","      <td>30.0</td>\n","      <td>Biotin</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Pantothenic acid</td>\n","      <td>5.0</td>\n","      <td>Pantothenic acid</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>Phosphorus</td>\n","      <td>1250.0</td>\n","      <td>Phosphorus, P</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>Magnesium</td>\n","      <td>420.0</td>\n","      <td>Magnesium, Mg</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>Zinc</td>\n","      <td>11.0</td>\n","      <td>Zinc, Zn</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>Selenium</td>\n","      <td>55.0</td>\n","      <td>Selenium, Se</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>Copper</td>\n","      <td>0.9</td>\n","      <td>Copper, Cu</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>Manganese</td>\n","      <td>2.3</td>\n","      <td>Manganese, Mn</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>Molybdenum</td>\n","      <td>45.0</td>\n","      <td>Molybdenum, Mo</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>Potassium</td>\n","      <td>4700.0</td>\n","      <td>Potassium, K</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>Choline</td>\n","      <td>550.0</td>\n","      <td>Choline, total</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29a25b68-0d73-448e-a8e7-efd3c51edc94')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-29a25b68-0d73-448e-a8e7-efd3c51edc94 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-29a25b68-0d73-448e-a8e7-efd3c51edc94');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":30}]},{"cell_type":"code","execution_count":null,"id":"9d541efe","metadata":{"id":"9d541efe"},"outputs":[],"source":["for ingredient in df.drop(columns=['rating']).columns:\n","    url = f'https://api.nal.usda.gov/fdc/v1/foods/search?api_key=4hSCFP3RWUJ6CAxHqZVN4g7VbS7ZyjJdDq4MAIue&query={ingredient}'\n","    res = requests.get(url).json()\n","    try:\n","        nutrients_info = res['foods'][0]['foodNutrients']\n","        nutrients_all = {}\n","        for nutrient_info in nutrients_info:\n","            nutrients_all[nutrient_info['nutrientName']] = nutrient_info['value']\n","        selected_nutrients = []\n","        for nutrient_api in nutrients.nutrient_api:\n","            selected_nutrients.append(nutrients_all.get(nutrient_api, 0.0))\n","        nutrients[ingredient] = selected_nutrients\n","    except:\n","        print(f'Информация о ингредиенте {ingredient} отсутствует')"]},{"cell_type":"code","execution_count":null,"id":"a1062b42","metadata":{"id":"a1062b42","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"1cf65881-137e-41ad-cb84-69bd423a8f82"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["               nutrient   value                    nutrient_api   almond  \\\n","0                   Fat    38.0               Total lipid (fat)   55.500   \n","1         Saturated fat    20.0    Fatty acids, total saturated    6.550   \n","2           Cholesterol   300.0                     Cholesterol    0.000   \n","3   Total carbohydrates   275.0     Carbohydrate, by difference   18.800   \n","4                Sodium  2300.0                      Sodium, Na  227.000   \n","5         Dietary Fiber    28.0            Fiber, total dietary   10.300   \n","6               Protein    50.0                         Protein   21.000   \n","7          Added sugars    50.0                   Sugars, added    0.000   \n","8             Vitamin A   900.0                  Vitamin A, RAE    0.000   \n","9             Vitamin C    90.0  Vitamin C, total ascorbic acid    0.000   \n","10              Calcium  1300.0                     Calcium, Ca  347.000   \n","11                 Iron    18.0                        Iron, Fe    3.490   \n","12            Vitamin D    20.0             Vitamin D (D2 + D3)    0.000   \n","13            Vitamin E    15.0    Vitamin E (alpha-tocopherol)   24.200   \n","14            Vitamin K   120.0       Vitamin K (phylloquinone)    0.000   \n","15              Thiamin     1.2                         Thiamin    0.041   \n","16           Riboflavin     1.3                      Riboflavin    0.939   \n","17               Niacin    16.0                          Niacin    3.160   \n","18           Vitamin B6     1.7                     Vitamin B-6    0.103   \n","19               Folate   400.0                     Folate, DFE   53.000   \n","20          Vitamin B12     2.4                    Vitamin B-12    0.000   \n","21               Biotin    30.0                          Biotin    0.000   \n","22     Pantothenic acid     5.0                Pantothenic acid    0.000   \n","23           Phosphorus  1250.0                   Phosphorus, P  508.000   \n","24            Magnesium   420.0                   Magnesium, Mg  279.000   \n","25                 Zinc    11.0                        Zinc, Zn    3.290   \n","26             Selenium    55.0                    Selenium, Se    2.400   \n","27               Copper     0.9                      Copper, Cu    0.934   \n","28            Manganese     2.3                   Manganese, Mn    0.000   \n","29           Molybdenum    45.0                  Molybdenum, Mo    0.000   \n","30            Potassium  4700.0                    Potassium, K  748.000   \n","31              Choline   550.0                  Choline, total   52.100   \n","\n","    amaretto   anchovy     anise   apple  apple juice  apricot  ...  \\\n","0      10.00     9.710    15.900    0.65         0.00      0.0  ...   \n","1       3.33     2.200     0.586    0.00         0.00      0.0  ...   \n","2       0.00    85.000     0.000    0.00         0.00      0.0  ...   \n","3      33.30     0.000    50.000   14.30        14.60     13.5  ...   \n","4      67.00  3670.000    16.000    0.00         0.00      6.0  ...   \n","5       0.00     0.000    14.600    3.20         0.00      0.0  ...   \n","6       0.00    28.900    17.600    0.00         0.42      0.0  ...   \n","7      33.30     0.000     0.000    0.00         0.00      0.0  ...   \n","8       0.00    12.000    16.000    0.00         0.00      0.0  ...   \n","9       0.00     0.000    21.000    3.10         0.00     17.6  ...   \n","10      0.00   232.000   646.000    0.00         0.00      0.0  ...   \n","11      0.00     4.630    37.000    0.23         0.00      0.0  ...   \n","12      0.00     1.700     0.000    0.00         0.00      0.0  ...   \n","13      0.00     3.330     0.000    0.00         0.00      0.0  ...   \n","14      0.00    12.100     0.000    0.00         0.00      0.0  ...   \n","15      0.00     0.078     0.340    0.00         0.00      0.0  ...   \n","16      0.00     0.363     0.290    0.00         0.00      0.0  ...   \n","17      0.00    19.900     3.060    0.00         0.00      0.0  ...   \n","18      0.00     0.203     0.650    0.00         0.00      0.0  ...   \n","19      0.00    13.000    10.000    0.00         0.00      0.0  ...   \n","20      0.00     0.880     0.000    0.00         0.00      0.0  ...   \n","21      0.00     0.000     0.000    0.00         0.00      0.0  ...   \n","22      0.00     0.000     0.797    0.00         0.00      0.0  ...   \n","23      0.00   252.000   440.000    0.00         0.00      0.0  ...   \n","24      0.00    69.000   170.000    0.00         0.00      0.0  ...   \n","25      0.00     2.440     5.300    0.00         0.00      0.0  ...   \n","26      0.00    68.100     5.000    0.00         0.00      0.0  ...   \n","27      0.00     0.339     0.910    0.00         0.00      0.0  ...   \n","28      0.00     0.000     2.300    0.00         0.00      0.0  ...   \n","29      0.00     0.000     0.000    0.00         0.00      0.0  ...   \n","30      0.00   544.000  1440.000  110.00        44.00     71.0  ...   \n","31      0.00    85.000     0.000    0.00         0.00      0.0  ...   \n","\n","    watermelon  whiskey  white wine  wild rice    wine  yellow squash  yogurt  \\\n","0         0.25    0.000       0.000      1.110   0.000           0.00    2.94   \n","1         0.00    0.000       0.000      0.000   0.000           0.00    1.76   \n","2         0.00    0.000       0.000      0.000   0.000           0.00   12.00   \n","3         7.45    0.000       2.600     77.800   5.000           4.08   15.90   \n","4         0.00    1.000       5.000      0.000   2.000           0.00   41.00   \n","5         0.40    0.000       0.000      4.400   0.000           2.00    0.00   \n","6         0.78    0.000       0.070     13.300   0.500           1.02    2.94   \n","7         0.00    0.000       0.000      0.000   0.000           0.00    0.00   \n","8         0.00    0.000       0.000      0.000   0.000           0.00    0.00   \n","9         0.00    0.000       0.000      0.000   0.000          18.40    0.70   \n","10        0.00    0.000       9.000      0.000   5.000          20.00  118.00   \n","11        0.00    0.040       0.270      1.600   0.100           0.37    0.00   \n","12        0.00    0.000       0.000      0.000   0.000           0.00    0.00   \n","13        0.00    0.000       0.000      0.000   0.000           0.00    0.00   \n","14        0.00    0.000       0.400      0.000   0.000           0.00    0.00   \n","15        0.00    0.006       0.005      0.000   0.000           0.00    0.00   \n","16        0.00    0.004       0.015      0.227   0.000           0.00    0.00   \n","17        0.00    0.013       0.108      6.670   0.000           0.00    0.00   \n","18        0.00    0.001       0.050      0.444   0.000           0.00    0.00   \n","19        0.00    0.000       1.000      0.000   0.000           0.00    0.00   \n","20        0.00    0.000       0.000      0.000   0.000           0.00    0.00   \n","21        0.00    0.000       0.000      0.000   0.000           0.00    0.00   \n","22        0.00    0.000       0.000      0.000   0.000           0.00    0.00   \n","23        0.00    4.000      18.000    333.000   6.000           0.00    0.00   \n","24        0.00    0.000      10.000      0.000   6.000           0.00    0.00   \n","25        0.00    0.040       0.120      3.330   0.020           0.00    0.00   \n","26        0.00    0.000       0.100      0.000   1.400           0.00    0.00   \n","27        0.00    0.021       0.004      0.000   0.009           0.00    0.00   \n","28        0.00    0.000       0.000      0.000   0.000           0.00    0.00   \n","29        0.00    0.000       0.000      0.000   0.000           0.00    0.00   \n","30        0.00    2.000      71.000    267.000  25.000           0.00    0.00   \n","31        0.00    0.000       4.300      0.000   0.000           0.00    0.00   \n","\n","      yuca  zucchini  turkey  \n","0     0.00      0.00    1.27  \n","1     0.00      0.00    0.42  \n","2     0.00      0.00   34.00  \n","3    18.90      4.21    6.78  \n","4   525.00      0.00  521.00  \n","5     0.00      1.10    1.30  \n","6     0.94      1.05    9.75  \n","7     0.00      0.00    0.00  \n","8     0.00      0.00    0.00  \n","9     0.00     12.60    0.00  \n","10    0.00     21.00   42.00  \n","11    0.00      0.44    1.14  \n","12    0.00      0.00    0.00  \n","13    0.00      0.00    0.00  \n","14    0.00      0.00    0.00  \n","15    0.00      0.00    0.00  \n","16    0.00      0.00    0.00  \n","17    0.00      0.00    0.00  \n","18    0.00      0.00    0.00  \n","19    0.00      0.00    0.00  \n","20    0.00      0.00    0.00  \n","21    0.00      0.00    0.00  \n","22    0.00      0.00    0.00  \n","23    0.00      0.00    0.00  \n","24    0.00      0.00    0.00  \n","25    0.00      0.00    0.00  \n","26    0.00      0.00    0.00  \n","27    0.00      0.00    0.00  \n","28    0.00      0.00    0.00  \n","29    0.00      0.00    0.00  \n","30    0.00    222.00    0.00  \n","31    0.00      0.00    0.00  \n","\n","[32 rows x 268 columns]"],"text/html":["\n","  <div id=\"df-a9f331e2-2fb3-466b-9df0-6d5f9b2d6837\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>nutrient</th>\n","      <th>value</th>\n","      <th>nutrient_api</th>\n","      <th>almond</th>\n","      <th>amaretto</th>\n","      <th>anchovy</th>\n","      <th>anise</th>\n","      <th>apple</th>\n","      <th>apple juice</th>\n","      <th>apricot</th>\n","      <th>...</th>\n","      <th>watermelon</th>\n","      <th>whiskey</th>\n","      <th>white wine</th>\n","      <th>wild rice</th>\n","      <th>wine</th>\n","      <th>yellow squash</th>\n","      <th>yogurt</th>\n","      <th>yuca</th>\n","      <th>zucchini</th>\n","      <th>turkey</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Fat</td>\n","      <td>38.0</td>\n","      <td>Total lipid (fat)</td>\n","      <td>55.500</td>\n","      <td>10.00</td>\n","      <td>9.710</td>\n","      <td>15.900</td>\n","      <td>0.65</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.25</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>1.110</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>2.94</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>1.27</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Saturated fat</td>\n","      <td>20.0</td>\n","      <td>Fatty acids, total saturated</td>\n","      <td>6.550</td>\n","      <td>3.33</td>\n","      <td>2.200</td>\n","      <td>0.586</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>1.76</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.42</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Cholesterol</td>\n","      <td>300.0</td>\n","      <td>Cholesterol</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>85.000</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>12.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>34.00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Total carbohydrates</td>\n","      <td>275.0</td>\n","      <td>Carbohydrate, by difference</td>\n","      <td>18.800</td>\n","      <td>33.30</td>\n","      <td>0.000</td>\n","      <td>50.000</td>\n","      <td>14.30</td>\n","      <td>14.60</td>\n","      <td>13.5</td>\n","      <td>...</td>\n","      <td>7.45</td>\n","      <td>0.000</td>\n","      <td>2.600</td>\n","      <td>77.800</td>\n","      <td>5.000</td>\n","      <td>4.08</td>\n","      <td>15.90</td>\n","      <td>18.90</td>\n","      <td>4.21</td>\n","      <td>6.78</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sodium</td>\n","      <td>2300.0</td>\n","      <td>Sodium, Na</td>\n","      <td>227.000</td>\n","      <td>67.00</td>\n","      <td>3670.000</td>\n","      <td>16.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>6.0</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>1.000</td>\n","      <td>5.000</td>\n","      <td>0.000</td>\n","      <td>2.000</td>\n","      <td>0.00</td>\n","      <td>41.00</td>\n","      <td>525.00</td>\n","      <td>0.00</td>\n","      <td>521.00</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Dietary Fiber</td>\n","      <td>28.0</td>\n","      <td>Fiber, total dietary</td>\n","      <td>10.300</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>14.600</td>\n","      <td>3.20</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.40</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>4.400</td>\n","      <td>0.000</td>\n","      <td>2.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>1.10</td>\n","      <td>1.30</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Protein</td>\n","      <td>50.0</td>\n","      <td>Protein</td>\n","      <td>21.000</td>\n","      <td>0.00</td>\n","      <td>28.900</td>\n","      <td>17.600</td>\n","      <td>0.00</td>\n","      <td>0.42</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.78</td>\n","      <td>0.000</td>\n","      <td>0.070</td>\n","      <td>13.300</td>\n","      <td>0.500</td>\n","      <td>1.02</td>\n","      <td>2.94</td>\n","      <td>0.94</td>\n","      <td>1.05</td>\n","      <td>9.75</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Added sugars</td>\n","      <td>50.0</td>\n","      <td>Sugars, added</td>\n","      <td>0.000</td>\n","      <td>33.30</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Vitamin A</td>\n","      <td>900.0</td>\n","      <td>Vitamin A, RAE</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>12.000</td>\n","      <td>16.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Vitamin C</td>\n","      <td>90.0</td>\n","      <td>Vitamin C, total ascorbic acid</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>21.000</td>\n","      <td>3.10</td>\n","      <td>0.00</td>\n","      <td>17.6</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>18.40</td>\n","      <td>0.70</td>\n","      <td>0.00</td>\n","      <td>12.60</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Calcium</td>\n","      <td>1300.0</td>\n","      <td>Calcium, Ca</td>\n","      <td>347.000</td>\n","      <td>0.00</td>\n","      <td>232.000</td>\n","      <td>646.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>9.000</td>\n","      <td>0.000</td>\n","      <td>5.000</td>\n","      <td>20.00</td>\n","      <td>118.00</td>\n","      <td>0.00</td>\n","      <td>21.00</td>\n","      <td>42.00</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Iron</td>\n","      <td>18.0</td>\n","      <td>Iron, Fe</td>\n","      <td>3.490</td>\n","      <td>0.00</td>\n","      <td>4.630</td>\n","      <td>37.000</td>\n","      <td>0.23</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.040</td>\n","      <td>0.270</td>\n","      <td>1.600</td>\n","      <td>0.100</td>\n","      <td>0.37</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.44</td>\n","      <td>1.14</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Vitamin D</td>\n","      <td>20.0</td>\n","      <td>Vitamin D (D2 + D3)</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>1.700</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Vitamin E</td>\n","      <td>15.0</td>\n","      <td>Vitamin E (alpha-tocopherol)</td>\n","      <td>24.200</td>\n","      <td>0.00</td>\n","      <td>3.330</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>Vitamin K</td>\n","      <td>120.0</td>\n","      <td>Vitamin K (phylloquinone)</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>12.100</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>0.400</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>Thiamin</td>\n","      <td>1.2</td>\n","      <td>Thiamin</td>\n","      <td>0.041</td>\n","      <td>0.00</td>\n","      <td>0.078</td>\n","      <td>0.340</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.006</td>\n","      <td>0.005</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>Riboflavin</td>\n","      <td>1.3</td>\n","      <td>Riboflavin</td>\n","      <td>0.939</td>\n","      <td>0.00</td>\n","      <td>0.363</td>\n","      <td>0.290</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.004</td>\n","      <td>0.015</td>\n","      <td>0.227</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>Niacin</td>\n","      <td>16.0</td>\n","      <td>Niacin</td>\n","      <td>3.160</td>\n","      <td>0.00</td>\n","      <td>19.900</td>\n","      <td>3.060</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.013</td>\n","      <td>0.108</td>\n","      <td>6.670</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>Vitamin B6</td>\n","      <td>1.7</td>\n","      <td>Vitamin B-6</td>\n","      <td>0.103</td>\n","      <td>0.00</td>\n","      <td>0.203</td>\n","      <td>0.650</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.001</td>\n","      <td>0.050</td>\n","      <td>0.444</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>Folate</td>\n","      <td>400.0</td>\n","      <td>Folate, DFE</td>\n","      <td>53.000</td>\n","      <td>0.00</td>\n","      <td>13.000</td>\n","      <td>10.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>1.000</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>Vitamin B12</td>\n","      <td>2.4</td>\n","      <td>Vitamin B-12</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.880</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>Biotin</td>\n","      <td>30.0</td>\n","      <td>Biotin</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Pantothenic acid</td>\n","      <td>5.0</td>\n","      <td>Pantothenic acid</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>0.797</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>Phosphorus</td>\n","      <td>1250.0</td>\n","      <td>Phosphorus, P</td>\n","      <td>508.000</td>\n","      <td>0.00</td>\n","      <td>252.000</td>\n","      <td>440.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>4.000</td>\n","      <td>18.000</td>\n","      <td>333.000</td>\n","      <td>6.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>Magnesium</td>\n","      <td>420.0</td>\n","      <td>Magnesium, Mg</td>\n","      <td>279.000</td>\n","      <td>0.00</td>\n","      <td>69.000</td>\n","      <td>170.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>10.000</td>\n","      <td>0.000</td>\n","      <td>6.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>Zinc</td>\n","      <td>11.0</td>\n","      <td>Zinc, Zn</td>\n","      <td>3.290</td>\n","      <td>0.00</td>\n","      <td>2.440</td>\n","      <td>5.300</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.040</td>\n","      <td>0.120</td>\n","      <td>3.330</td>\n","      <td>0.020</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>Selenium</td>\n","      <td>55.0</td>\n","      <td>Selenium, Se</td>\n","      <td>2.400</td>\n","      <td>0.00</td>\n","      <td>68.100</td>\n","      <td>5.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>0.100</td>\n","      <td>0.000</td>\n","      <td>1.400</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>Copper</td>\n","      <td>0.9</td>\n","      <td>Copper, Cu</td>\n","      <td>0.934</td>\n","      <td>0.00</td>\n","      <td>0.339</td>\n","      <td>0.910</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.021</td>\n","      <td>0.004</td>\n","      <td>0.000</td>\n","      <td>0.009</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>Manganese</td>\n","      <td>2.3</td>\n","      <td>Manganese, Mn</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>2.300</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>Molybdenum</td>\n","      <td>45.0</td>\n","      <td>Molybdenum, Mo</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>Potassium</td>\n","      <td>4700.0</td>\n","      <td>Potassium, K</td>\n","      <td>748.000</td>\n","      <td>0.00</td>\n","      <td>544.000</td>\n","      <td>1440.000</td>\n","      <td>110.00</td>\n","      <td>44.00</td>\n","      <td>71.0</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>2.000</td>\n","      <td>71.000</td>\n","      <td>267.000</td>\n","      <td>25.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>222.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>Choline</td>\n","      <td>550.0</td>\n","      <td>Choline, total</td>\n","      <td>52.100</td>\n","      <td>0.00</td>\n","      <td>85.000</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>4.300</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>32 rows × 268 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9f331e2-2fb3-466b-9df0-6d5f9b2d6837')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a9f331e2-2fb3-466b-9df0-6d5f9b2d6837 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a9f331e2-2fb3-466b-9df0-6d5f9b2d6837');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":32}],"source":["nutrients"]},{"cell_type":"code","execution_count":null,"id":"5f912b9f","metadata":{"id":"5f912b9f"},"outputs":[],"source":["nutrients = nutrients[['nutrient', 'value', 'nutrient_api']].join(nutrients.drop(columns=['nutrient', 'value', 'nutrient_api']).apply(lambda x: x / nutrients['value'] * 100, axis=0))"]},{"cell_type":"code","source":["nutrients"],"metadata":{"id":"n_yd1tUwpEMV","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"10f6bc2f-294b-4132-a04f-f6a66d22a233"},"id":"n_yd1tUwpEMV","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               nutrient   value                    nutrient_api      almond  \\\n","0                   Fat    38.0               Total lipid (fat)  146.052632   \n","1         Saturated fat    20.0    Fatty acids, total saturated   32.750000   \n","2           Cholesterol   300.0                     Cholesterol    0.000000   \n","3   Total carbohydrates   275.0     Carbohydrate, by difference    6.836364   \n","4                Sodium  2300.0                      Sodium, Na    9.869565   \n","5         Dietary Fiber    28.0            Fiber, total dietary   36.785714   \n","6               Protein    50.0                         Protein   42.000000   \n","7          Added sugars    50.0                   Sugars, added    0.000000   \n","8             Vitamin A   900.0                  Vitamin A, RAE    0.000000   \n","9             Vitamin C    90.0  Vitamin C, total ascorbic acid    0.000000   \n","10              Calcium  1300.0                     Calcium, Ca   26.692308   \n","11                 Iron    18.0                        Iron, Fe   19.388889   \n","12            Vitamin D    20.0             Vitamin D (D2 + D3)    0.000000   \n","13            Vitamin E    15.0    Vitamin E (alpha-tocopherol)  161.333333   \n","14            Vitamin K   120.0       Vitamin K (phylloquinone)    0.000000   \n","15              Thiamin     1.2                         Thiamin    3.416667   \n","16           Riboflavin     1.3                      Riboflavin   72.230769   \n","17               Niacin    16.0                          Niacin   19.750000   \n","18           Vitamin B6     1.7                     Vitamin B-6    6.058824   \n","19               Folate   400.0                     Folate, DFE   13.250000   \n","20          Vitamin B12     2.4                    Vitamin B-12    0.000000   \n","21               Biotin    30.0                          Biotin    0.000000   \n","22     Pantothenic acid     5.0                Pantothenic acid    0.000000   \n","23           Phosphorus  1250.0                   Phosphorus, P   40.640000   \n","24            Magnesium   420.0                   Magnesium, Mg   66.428571   \n","25                 Zinc    11.0                        Zinc, Zn   29.909091   \n","26             Selenium    55.0                    Selenium, Se    4.363636   \n","27               Copper     0.9                      Copper, Cu  103.777778   \n","28            Manganese     2.3                   Manganese, Mn    0.000000   \n","29           Molybdenum    45.0                  Molybdenum, Mo    0.000000   \n","30            Potassium  4700.0                    Potassium, K   15.914894   \n","31              Choline   550.0                  Choline, total    9.472727   \n","\n","     amaretto     anchovy       anise      apple  apple juice    apricot  ...  \\\n","0   26.315789   25.552632   41.842105   1.710526     0.000000   0.000000  ...   \n","1   16.650000   11.000000    2.930000   0.000000     0.000000   0.000000  ...   \n","2    0.000000   28.333333    0.000000   0.000000     0.000000   0.000000  ...   \n","3   12.109091    0.000000   18.181818   5.200000     5.309091   4.909091  ...   \n","4    2.913043  159.565217    0.695652   0.000000     0.000000   0.260870  ...   \n","5    0.000000    0.000000   52.142857  11.428571     0.000000   0.000000  ...   \n","6    0.000000   57.800000   35.200000   0.000000     0.840000   0.000000  ...   \n","7   66.600000    0.000000    0.000000   0.000000     0.000000   0.000000  ...   \n","8    0.000000    1.333333    1.777778   0.000000     0.000000   0.000000  ...   \n","9    0.000000    0.000000   23.333333   3.444444     0.000000  19.555556  ...   \n","10   0.000000   17.846154   49.692308   0.000000     0.000000   0.000000  ...   \n","11   0.000000   25.722222  205.555556   1.277778     0.000000   0.000000  ...   \n","12   0.000000    8.500000    0.000000   0.000000     0.000000   0.000000  ...   \n","13   0.000000   22.200000    0.000000   0.000000     0.000000   0.000000  ...   \n","14   0.000000   10.083333    0.000000   0.000000     0.000000   0.000000  ...   \n","15   0.000000    6.500000   28.333333   0.000000     0.000000   0.000000  ...   \n","16   0.000000   27.923077   22.307692   0.000000     0.000000   0.000000  ...   \n","17   0.000000  124.375000   19.125000   0.000000     0.000000   0.000000  ...   \n","18   0.000000   11.941176   38.235294   0.000000     0.000000   0.000000  ...   \n","19   0.000000    3.250000    2.500000   0.000000     0.000000   0.000000  ...   \n","20   0.000000   36.666667    0.000000   0.000000     0.000000   0.000000  ...   \n","21   0.000000    0.000000    0.000000   0.000000     0.000000   0.000000  ...   \n","22   0.000000    0.000000   15.940000   0.000000     0.000000   0.000000  ...   \n","23   0.000000   20.160000   35.200000   0.000000     0.000000   0.000000  ...   \n","24   0.000000   16.428571   40.476190   0.000000     0.000000   0.000000  ...   \n","25   0.000000   22.181818   48.181818   0.000000     0.000000   0.000000  ...   \n","26   0.000000  123.818182    9.090909   0.000000     0.000000   0.000000  ...   \n","27   0.000000   37.666667  101.111111   0.000000     0.000000   0.000000  ...   \n","28   0.000000    0.000000  100.000000   0.000000     0.000000   0.000000  ...   \n","29   0.000000    0.000000    0.000000   0.000000     0.000000   0.000000  ...   \n","30   0.000000   11.574468   30.638298   2.340426     0.936170   1.510638  ...   \n","31   0.000000   15.454545    0.000000   0.000000     0.000000   0.000000  ...   \n","\n","    watermelon   whiskey  white wine  wild rice      wine  yellow squash  \\\n","0     0.657895  0.000000    0.000000   2.921053  0.000000       0.000000   \n","1     0.000000  0.000000    0.000000   0.000000  0.000000       0.000000   \n","2     0.000000  0.000000    0.000000   0.000000  0.000000       0.000000   \n","3     2.709091  0.000000    0.945455  28.290909  1.818182       1.483636   \n","4     0.000000  0.043478    0.217391   0.000000  0.086957       0.000000   \n","5     1.428571  0.000000    0.000000  15.714286  0.000000       7.142857   \n","6     1.560000  0.000000    0.140000  26.600000  1.000000       2.040000   \n","7     0.000000  0.000000    0.000000   0.000000  0.000000       0.000000   \n","8     0.000000  0.000000    0.000000   0.000000  0.000000       0.000000   \n","9     0.000000  0.000000    0.000000   0.000000  0.000000      20.444444   \n","10    0.000000  0.000000    0.692308   0.000000  0.384615       1.538462   \n","11    0.000000  0.222222    1.500000   8.888889  0.555556       2.055556   \n","12    0.000000  0.000000    0.000000   0.000000  0.000000       0.000000   \n","13    0.000000  0.000000    0.000000   0.000000  0.000000       0.000000   \n","14    0.000000  0.000000    0.333333   0.000000  0.000000       0.000000   \n","15    0.000000  0.500000    0.416667   0.000000  0.000000       0.000000   \n","16    0.000000  0.307692    1.153846  17.461538  0.000000       0.000000   \n","17    0.000000  0.081250    0.675000  41.687500  0.000000       0.000000   \n","18    0.000000  0.058824    2.941176  26.117647  0.000000       0.000000   \n","19    0.000000  0.000000    0.250000   0.000000  0.000000       0.000000   \n","20    0.000000  0.000000    0.000000   0.000000  0.000000       0.000000   \n","21    0.000000  0.000000    0.000000   0.000000  0.000000       0.000000   \n","22    0.000000  0.000000    0.000000   0.000000  0.000000       0.000000   \n","23    0.000000  0.320000    1.440000  26.640000  0.480000       0.000000   \n","24    0.000000  0.000000    2.380952   0.000000  1.428571       0.000000   \n","25    0.000000  0.363636    1.090909  30.272727  0.181818       0.000000   \n","26    0.000000  0.000000    0.181818   0.000000  2.545455       0.000000   \n","27    0.000000  2.333333    0.444444   0.000000  1.000000       0.000000   \n","28    0.000000  0.000000    0.000000   0.000000  0.000000       0.000000   \n","29    0.000000  0.000000    0.000000   0.000000  0.000000       0.000000   \n","30    0.000000  0.042553    1.510638   5.680851  0.531915       0.000000   \n","31    0.000000  0.000000    0.781818   0.000000  0.000000       0.000000   \n","\n","      yogurt       yuca   zucchini     turkey  \n","0   7.736842   0.000000   0.000000   3.342105  \n","1   8.800000   0.000000   0.000000   2.100000  \n","2   4.000000   0.000000   0.000000  11.333333  \n","3   5.781818   6.872727   1.530909   2.465455  \n","4   1.782609  22.826087   0.000000  22.652174  \n","5   0.000000   0.000000   3.928571   4.642857  \n","6   5.880000   1.880000   2.100000  19.500000  \n","7   0.000000   0.000000   0.000000   0.000000  \n","8   0.000000   0.000000   0.000000   0.000000  \n","9   0.777778   0.000000  14.000000   0.000000  \n","10  9.076923   0.000000   1.615385   3.230769  \n","11  0.000000   0.000000   2.444444   6.333333  \n","12  0.000000   0.000000   0.000000   0.000000  \n","13  0.000000   0.000000   0.000000   0.000000  \n","14  0.000000   0.000000   0.000000   0.000000  \n","15  0.000000   0.000000   0.000000   0.000000  \n","16  0.000000   0.000000   0.000000   0.000000  \n","17  0.000000   0.000000   0.000000   0.000000  \n","18  0.000000   0.000000   0.000000   0.000000  \n","19  0.000000   0.000000   0.000000   0.000000  \n","20  0.000000   0.000000   0.000000   0.000000  \n","21  0.000000   0.000000   0.000000   0.000000  \n","22  0.000000   0.000000   0.000000   0.000000  \n","23  0.000000   0.000000   0.000000   0.000000  \n","24  0.000000   0.000000   0.000000   0.000000  \n","25  0.000000   0.000000   0.000000   0.000000  \n","26  0.000000   0.000000   0.000000   0.000000  \n","27  0.000000   0.000000   0.000000   0.000000  \n","28  0.000000   0.000000   0.000000   0.000000  \n","29  0.000000   0.000000   0.000000   0.000000  \n","30  0.000000   0.000000   4.723404   0.000000  \n","31  0.000000   0.000000   0.000000   0.000000  \n","\n","[32 rows x 268 columns]"],"text/html":["\n","  <div id=\"df-44d966d8-9d62-4965-9317-70e55050954f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>nutrient</th>\n","      <th>value</th>\n","      <th>nutrient_api</th>\n","      <th>almond</th>\n","      <th>amaretto</th>\n","      <th>anchovy</th>\n","      <th>anise</th>\n","      <th>apple</th>\n","      <th>apple juice</th>\n","      <th>apricot</th>\n","      <th>...</th>\n","      <th>watermelon</th>\n","      <th>whiskey</th>\n","      <th>white wine</th>\n","      <th>wild rice</th>\n","      <th>wine</th>\n","      <th>yellow squash</th>\n","      <th>yogurt</th>\n","      <th>yuca</th>\n","      <th>zucchini</th>\n","      <th>turkey</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Fat</td>\n","      <td>38.0</td>\n","      <td>Total lipid (fat)</td>\n","      <td>146.052632</td>\n","      <td>26.315789</td>\n","      <td>25.552632</td>\n","      <td>41.842105</td>\n","      <td>1.710526</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.657895</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>2.921053</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>7.736842</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>3.342105</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Saturated fat</td>\n","      <td>20.0</td>\n","      <td>Fatty acids, total saturated</td>\n","      <td>32.750000</td>\n","      <td>16.650000</td>\n","      <td>11.000000</td>\n","      <td>2.930000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>8.800000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>2.100000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Cholesterol</td>\n","      <td>300.0</td>\n","      <td>Cholesterol</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>28.333333</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>4.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>11.333333</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Total carbohydrates</td>\n","      <td>275.0</td>\n","      <td>Carbohydrate, by difference</td>\n","      <td>6.836364</td>\n","      <td>12.109091</td>\n","      <td>0.000000</td>\n","      <td>18.181818</td>\n","      <td>5.200000</td>\n","      <td>5.309091</td>\n","      <td>4.909091</td>\n","      <td>...</td>\n","      <td>2.709091</td>\n","      <td>0.000000</td>\n","      <td>0.945455</td>\n","      <td>28.290909</td>\n","      <td>1.818182</td>\n","      <td>1.483636</td>\n","      <td>5.781818</td>\n","      <td>6.872727</td>\n","      <td>1.530909</td>\n","      <td>2.465455</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sodium</td>\n","      <td>2300.0</td>\n","      <td>Sodium, Na</td>\n","      <td>9.869565</td>\n","      <td>2.913043</td>\n","      <td>159.565217</td>\n","      <td>0.695652</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.260870</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.043478</td>\n","      <td>0.217391</td>\n","      <td>0.000000</td>\n","      <td>0.086957</td>\n","      <td>0.000000</td>\n","      <td>1.782609</td>\n","      <td>22.826087</td>\n","      <td>0.000000</td>\n","      <td>22.652174</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Dietary Fiber</td>\n","      <td>28.0</td>\n","      <td>Fiber, total dietary</td>\n","      <td>36.785714</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>52.142857</td>\n","      <td>11.428571</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>1.428571</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>15.714286</td>\n","      <td>0.000000</td>\n","      <td>7.142857</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>3.928571</td>\n","      <td>4.642857</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Protein</td>\n","      <td>50.0</td>\n","      <td>Protein</td>\n","      <td>42.000000</td>\n","      <td>0.000000</td>\n","      <td>57.800000</td>\n","      <td>35.200000</td>\n","      <td>0.000000</td>\n","      <td>0.840000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>1.560000</td>\n","      <td>0.000000</td>\n","      <td>0.140000</td>\n","      <td>26.600000</td>\n","      <td>1.000000</td>\n","      <td>2.040000</td>\n","      <td>5.880000</td>\n","      <td>1.880000</td>\n","      <td>2.100000</td>\n","      <td>19.500000</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Added sugars</td>\n","      <td>50.0</td>\n","      <td>Sugars, added</td>\n","      <td>0.000000</td>\n","      <td>66.600000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Vitamin A</td>\n","      <td>900.0</td>\n","      <td>Vitamin A, RAE</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.333333</td>\n","      <td>1.777778</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Vitamin C</td>\n","      <td>90.0</td>\n","      <td>Vitamin C, total ascorbic acid</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>23.333333</td>\n","      <td>3.444444</td>\n","      <td>0.000000</td>\n","      <td>19.555556</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>20.444444</td>\n","      <td>0.777778</td>\n","      <td>0.000000</td>\n","      <td>14.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Calcium</td>\n","      <td>1300.0</td>\n","      <td>Calcium, Ca</td>\n","      <td>26.692308</td>\n","      <td>0.000000</td>\n","      <td>17.846154</td>\n","      <td>49.692308</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.692308</td>\n","      <td>0.000000</td>\n","      <td>0.384615</td>\n","      <td>1.538462</td>\n","      <td>9.076923</td>\n","      <td>0.000000</td>\n","      <td>1.615385</td>\n","      <td>3.230769</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Iron</td>\n","      <td>18.0</td>\n","      <td>Iron, Fe</td>\n","      <td>19.388889</td>\n","      <td>0.000000</td>\n","      <td>25.722222</td>\n","      <td>205.555556</td>\n","      <td>1.277778</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.222222</td>\n","      <td>1.500000</td>\n","      <td>8.888889</td>\n","      <td>0.555556</td>\n","      <td>2.055556</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>2.444444</td>\n","      <td>6.333333</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Vitamin D</td>\n","      <td>20.0</td>\n","      <td>Vitamin D (D2 + D3)</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>8.500000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Vitamin E</td>\n","      <td>15.0</td>\n","      <td>Vitamin E (alpha-tocopherol)</td>\n","      <td>161.333333</td>\n","      <td>0.000000</td>\n","      <td>22.200000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>Vitamin K</td>\n","      <td>120.0</td>\n","      <td>Vitamin K (phylloquinone)</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>10.083333</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.333333</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>Thiamin</td>\n","      <td>1.2</td>\n","      <td>Thiamin</td>\n","      <td>3.416667</td>\n","      <td>0.000000</td>\n","      <td>6.500000</td>\n","      <td>28.333333</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.500000</td>\n","      <td>0.416667</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>Riboflavin</td>\n","      <td>1.3</td>\n","      <td>Riboflavin</td>\n","      <td>72.230769</td>\n","      <td>0.000000</td>\n","      <td>27.923077</td>\n","      <td>22.307692</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.307692</td>\n","      <td>1.153846</td>\n","      <td>17.461538</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>Niacin</td>\n","      <td>16.0</td>\n","      <td>Niacin</td>\n","      <td>19.750000</td>\n","      <td>0.000000</td>\n","      <td>124.375000</td>\n","      <td>19.125000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.081250</td>\n","      <td>0.675000</td>\n","      <td>41.687500</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>Vitamin B6</td>\n","      <td>1.7</td>\n","      <td>Vitamin B-6</td>\n","      <td>6.058824</td>\n","      <td>0.000000</td>\n","      <td>11.941176</td>\n","      <td>38.235294</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.058824</td>\n","      <td>2.941176</td>\n","      <td>26.117647</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>Folate</td>\n","      <td>400.0</td>\n","      <td>Folate, DFE</td>\n","      <td>13.250000</td>\n","      <td>0.000000</td>\n","      <td>3.250000</td>\n","      <td>2.500000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.250000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>Vitamin B12</td>\n","      <td>2.4</td>\n","      <td>Vitamin B-12</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>36.666667</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>Biotin</td>\n","      <td>30.0</td>\n","      <td>Biotin</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Pantothenic acid</td>\n","      <td>5.0</td>\n","      <td>Pantothenic acid</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>15.940000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>Phosphorus</td>\n","      <td>1250.0</td>\n","      <td>Phosphorus, P</td>\n","      <td>40.640000</td>\n","      <td>0.000000</td>\n","      <td>20.160000</td>\n","      <td>35.200000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.320000</td>\n","      <td>1.440000</td>\n","      <td>26.640000</td>\n","      <td>0.480000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>Magnesium</td>\n","      <td>420.0</td>\n","      <td>Magnesium, Mg</td>\n","      <td>66.428571</td>\n","      <td>0.000000</td>\n","      <td>16.428571</td>\n","      <td>40.476190</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>2.380952</td>\n","      <td>0.000000</td>\n","      <td>1.428571</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>Zinc</td>\n","      <td>11.0</td>\n","      <td>Zinc, Zn</td>\n","      <td>29.909091</td>\n","      <td>0.000000</td>\n","      <td>22.181818</td>\n","      <td>48.181818</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.363636</td>\n","      <td>1.090909</td>\n","      <td>30.272727</td>\n","      <td>0.181818</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>Selenium</td>\n","      <td>55.0</td>\n","      <td>Selenium, Se</td>\n","      <td>4.363636</td>\n","      <td>0.000000</td>\n","      <td>123.818182</td>\n","      <td>9.090909</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.181818</td>\n","      <td>0.000000</td>\n","      <td>2.545455</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>Copper</td>\n","      <td>0.9</td>\n","      <td>Copper, Cu</td>\n","      <td>103.777778</td>\n","      <td>0.000000</td>\n","      <td>37.666667</td>\n","      <td>101.111111</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>2.333333</td>\n","      <td>0.444444</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>Manganese</td>\n","      <td>2.3</td>\n","      <td>Manganese, Mn</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>100.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>Molybdenum</td>\n","      <td>45.0</td>\n","      <td>Molybdenum, Mo</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>Potassium</td>\n","      <td>4700.0</td>\n","      <td>Potassium, K</td>\n","      <td>15.914894</td>\n","      <td>0.000000</td>\n","      <td>11.574468</td>\n","      <td>30.638298</td>\n","      <td>2.340426</td>\n","      <td>0.936170</td>\n","      <td>1.510638</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.042553</td>\n","      <td>1.510638</td>\n","      <td>5.680851</td>\n","      <td>0.531915</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>4.723404</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>Choline</td>\n","      <td>550.0</td>\n","      <td>Choline, total</td>\n","      <td>9.472727</td>\n","      <td>0.000000</td>\n","      <td>15.454545</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.781818</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>32 rows × 268 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44d966d8-9d62-4965-9317-70e55050954f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-44d966d8-9d62-4965-9317-70e55050954f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-44d966d8-9d62-4965-9317-70e55050954f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":34}]},{"cell_type":"code","execution_count":null,"id":"f44d6302","metadata":{"id":"f44d6302"},"outputs":[],"source":["nutrients.to_csv('nutrients.csv', index=False)"]},{"cell_type":"code","execution_count":null,"id":"f7fde1ab","metadata":{"id":"f7fde1ab"},"outputs":[],"source":["nutrients = pd.read_csv('nutrients.csv')\n","nutrients"]},{"cell_type":"markdown","id":"05f93263","metadata":{"id":"05f93263"},"source":["# Похожие рецепты"]},{"cell_type":"code","execution_count":null,"id":"c1e58343","metadata":{"id":"c1e58343"},"outputs":[],"source":["#функция для парсинга ссылок по названию блюда (title)\n","def get_link(title):\n","    title = title.rstrip()\n","    title = unidecode.unidecode(title)\n","    recipe = title.replace('\"','').replace('’','').replace(' ', '%20')\n","    url = f'https://www.epicurious.com/search/{recipe}'\n","    page = requests.get(url)\n","    if page.status_code != 200:\n","        try:\n","            return next(search(title, stop=1))\n","        except:\n","            print(title)\n","            return None\n","    try:\n","        soup = BeautifulSoup(page.text, \"html.parser\")\n","        return 'https://www.epicurious.com' + soup.select('div.results-group article.recipe-content-card a.view-complete-item')[0]['href']\n","    except:\n","        try:\n","            return next(search(title, stop=1))\n","        except:\n","            print(title)\n","            return None"]},{"cell_type":"code","execution_count":null,"id":"34f01b05","metadata":{"id":"34f01b05"},"outputs":[],"source":["#собираем необходимые url\n","links = []\n","for title in recipes.title:\n","    links.append(get_link(title))"]},{"cell_type":"code","execution_count":null,"id":"44218242","metadata":{"id":"44218242"},"outputs":[],"source":["#заполняем колонку с url в нашем файле recipes\n","recipes['link'] = links"]},{"cell_type":"code","execution_count":null,"id":"94873bb8","metadata":{"id":"94873bb8"},"outputs":[],"source":["recipes.duplicated().sum()"]},{"cell_type":"code","execution_count":null,"id":"db8d03a7","metadata":{"id":"db8d03a7"},"outputs":[],"source":["recipes.drop_duplicates(inplace=True)"]},{"cell_type":"code","execution_count":null,"id":"838d3fa6","metadata":{"id":"838d3fa6"},"outputs":[],"source":["recipes.duplicated().sum()"]},{"cell_type":"code","execution_count":null,"id":"7dac942c","metadata":{"id":"7dac942c"},"outputs":[],"source":["recipes.to_csv('recipes.csv', index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[],"collapsed_sections":["875a9ad0","04298bde","6742ff49","85d03ede","2a4672ce","9f467eb6","c97eefc0","9ac0a4a6","fbf291f0","f15e2679","27070937","2305b8ad","37ed68b7","0da181b4","e731016c","677083f6","b79d2e17","0c620cb2","3f2ed732","1eee3c6a","e7c811ea","57cd23e7","d7efab1e","8af8ed2d","3edbf740","ad77fedb","c7850d81","e1307e33","50658dff","cd8b3e88","c7b5862d"]},"gpuClass":"standard","accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}